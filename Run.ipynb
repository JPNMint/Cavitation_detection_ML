{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scripts.model import Classification_pipe_all\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "split_eval_list = np.arange(0.1,0.5,0.1)\n",
    "    #np.arange(1,2.2,0.5)\n",
    "No_cav_files = [\"sxmany_200206_007_HKMNetzpumpe04_004_RP1_FC_01_C06_SB1_L0_XX_XXXX_YY_YYYY_ZZZZZZ_10.wav\"]\n",
    "cav_files = [\"s00000_191115_007_KesselpumpHD02_002_RP1_FC_01_P06_SB1_L0_KS_XXXX_YY_YYYY_ZZZZZZ_16.wav\"]\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Window size evaluation is set to true, range is [0.1 0.2 0.3 0.4]\n",
      "\n",
      " Evaluation method is f1\n",
      "0.1 second splits\n",
      "\n",
      " Train set: 280 samples!\n",
      "\n",
      " Test set: 120 samples!\n",
      "\n",
      " -------------------------------\n",
      "\n",
      " Fitting XGBoost!\n",
      "\n",
      " Train set: 280 samples!,  Test set: 120 samples!\n",
      "\n",
      " Classification report on unseen test set:\n",
      "\n",
      " accuracy:1.0, f1: 1.0\n",
      "\n",
      " -------------------------------------\n",
      "0.2 second splits\n",
      "\n",
      " Train set: 140 samples!\n",
      "\n",
      " Test set: 60 samples!\n",
      "\n",
      " -------------------------------\n",
      "\n",
      " Fitting XGBoost!\n",
      "\n",
      " Train set: 140 samples!,  Test set: 60 samples!\n",
      "\n",
      " Classification report on unseen test set:\n",
      "\n",
      " accuracy:1.0, f1: 1.0\n",
      "\n",
      " -------------------------------------\n",
      "0.30000000000000004 second splits\n",
      "\n",
      " Train set: 93 samples!\n",
      "\n",
      " Test set: 41 samples!\n",
      "\n",
      " -------------------------------\n",
      "\n",
      " Fitting XGBoost!\n",
      "\n",
      " Train set: 93 samples!,  Test set: 41 samples!\n",
      "\n",
      " Classification report on unseen test set:\n",
      "\n",
      " accuracy:0.975609756097561, f1: 0.975609756097561\n",
      "\n",
      " -------------------------------------\n",
      "0.4 second splits\n",
      "\n",
      " Train set: 70 samples!\n",
      "\n",
      " Test set: 30 samples!\n",
      "\n",
      " -------------------------------\n",
      "\n",
      " Fitting XGBoost!\n",
      "\n",
      " Train set: 70 samples!,  Test set: 30 samples!\n",
      "\n",
      " Classification report on unseen test set:\n",
      "\n",
      " accuracy:1.0, f1: 1.0\n",
      "\n",
      " -------------------------------------\n",
      "\n",
      " RESULT: window size evaulation based on f1, best split size is 0.1 seconds!\n",
      "\n",
      " Train set: 175 samples!\n",
      "\n",
      " Test set: 75 samples!\n",
      "\n",
      " ----------------------------------------------\n",
      "\n",
      " Initiating Gridsearch, fine tuning parameters!\n",
      "\n",
      " Scoring: f1\n",
      "Fitting 10 folds for each of 216 candidates, totalling 2160 fits\n",
      "\n",
      " Done!\n",
      "\n",
      " Best estimator:\n",
      "XGBClassifier(base_score=0.5, booster='gbtree', callbacks=None,\n",
      "              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
      "              early_stopping_rounds=None, enable_categorical=False,\n",
      "              eval_metric=None, gamma=0, gpu_id=-1, grow_policy='depthwise',\n",
      "              importance_type=None, interaction_constraints='',\n",
      "              learning_rate=0.1, max_bin=256, max_cat_to_onehot=4,\n",
      "              max_delta_step=0, max_depth=2, max_leaves=0, min_child_weight=1,\n",
      "              missing=nan, monotone_constraints='()', n_estimators=100,\n",
      "              n_jobs=0, num_parallel_tree=1, predictor='auto', random_state=0,\n",
      "              reg_alpha=0, reg_lambda=1, ...)\n",
      "\n",
      "  best_score_:\n",
      "1.0\n",
      "\n",
      " Best parameters:\n",
      "{'learning_rate': 0.1, 'max_depth': 2, 'n_estimators': 100}\n",
      "\n",
      " Feature importance:\n",
      "       Variable  Importance\n",
      "2   quartile_25    0.820424\n",
      "10           ff    0.057465\n",
      "6      quartile    0.039012\n",
      "7           std    0.028915\n",
      "11          clf    0.028141\n",
      "13     kurtosis    0.026044\n",
      "0          mean    0.000000\n",
      "1        median    0.000000\n",
      "3   quartile_75    0.000000\n",
      "4           Max    0.000000\n",
      "5           Min    0.000000\n",
      "8           rms    0.000000\n",
      "9           sra    0.000000\n",
      "12           cf    0.000000\n",
      "14         skew    0.000000\n",
      "\n",
      " Classification report on unseen test set:\n",
      "\n",
      " accuracy:1.0, f1: 1.0\n"
     ]
    }
   ],
   "source": [
    "param = {\n",
    "            'max_depth': range (2, 10, 1),\n",
    "            'n_estimators': range(100, 1000, 100),\n",
    "            'learning_rate': [0.1, 0.01, 0.05]\n",
    "        }\n",
    "train, test, model, eval_df  = Classification_pipe_all (split_eval_list,  cav_files, No_cav_files, 0.3 , parameter = param,evaluation = \"f1\" , window_size_eval = True, gridsearch = False)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# list of window sizes (if split_eval is set to true, otherwise only 1 window size) , list of cavitation files, list of no-cavitation files, train test split, evaluation method, window size evaluation\n",
    "\n",
    "train, test, model, eval_df  = Classification_pipe_all (split_eval_list,  cav_files, No_cav_files, 0.3 , evaluation = \"accuracy\" , window_size_eval =True,  gridsearch = True) #grid, splits eval training"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}