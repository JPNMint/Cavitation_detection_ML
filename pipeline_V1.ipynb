{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "### Read data (wav)\n",
    "First read in high cavitation files."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from scipy.io import wavfile\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "def read_wav(dataset_names):\n",
    "    samplerate = []\n",
    "    df = []\n",
    "    for data in dataset_names:\n",
    "        path =  Path.cwd()/\"data\"\n",
    "        sf, d = wavfile.read(path/data)\n",
    "        samplerate.append(sf)\n",
    "        df.append(d)\n",
    "    return samplerate , df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kinos\\AppData\\Local\\Temp\\ipykernel_23192\\3207606025.py:6: WavFileWarning: Chunk (non-data) not understood, skipping it.\n",
      "  sf, d = wavfile.read(path/data)\n"
     ]
    }
   ],
   "source": [
    "datasets = [\"s00000_191115_007_KesselpumpHD02_002_RP1_FC_01_P06_SB1_L0_KS_XXXX_YY_YYYY_ZZZZZZ_16.wav\"]\n",
    "#,\"sxmany_200206_007_HKMNetzpumpe04_004_RP1_FC_01_C06_SB1_L0_XX_XXXX_YY_YYYY_ZZZZZZ_10.wav\"\n",
    "sr, df = read_wav(datasets)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Splitting\n",
    "\n",
    "Splitting the data in 2 second samples"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "\n",
    "def splitting (sr, df, sec):\n",
    "    #get sr for section\n",
    "    seg_len = int(sr * sec)\n",
    "\n",
    "    splits = []\n",
    "\n",
    "    for data in df:\n",
    "        #get number of sections\n",
    "        sections = int(np.ceil(len(data) / seg_len))\n",
    "        for i in range(sections):\n",
    "            #slice section range\n",
    "            t = data[i * seg_len: (i + 1) * seg_len]\n",
    "            splits.append(t)\n",
    "\n",
    "\n",
    "    return splits"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "df_split = splitting(sr[0],df, 1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "[array([ 133., 2008.,  909., ..., 4752., 1082., -561.], dtype=float32),\n array([ -222.,  -389., -3966., ...,  3011., -1090., -3151.], dtype=float32),\n array([ -7008., -11294., -10281., ..., -10713.,  -7686.,   -586.],\n       dtype=float32),\n array([ 7773., 11353.,  6606., ...,  -945., -2227., -2479.], dtype=float32),\n array([ -7246., -10567.,  -6030., ...,   6664.,   9614.,   6304.],\n       dtype=float32),\n array([ 1553.,  -702., -1371., ...,  3361.,  2102.,  -871.], dtype=float32),\n array([-3873., -3091., -5118., ...,  5502.,  -540., -5745.], dtype=float32),\n array([-10082., -10257.,  -7002., ...,    986.,   1313.,    437.],\n       dtype=float32),\n array([-1555., -2960., -2002., ..., -1487., -7882., -9647.], dtype=float32),\n array([-6543., -6708., -5260., ...,   988.,  4185.,  9247.], dtype=float32),\n array([ 7411.,   687., -6734., ...,   857.,  -887., -1447.], dtype=float32),\n array([ -2107.,  -2305.,  -5049., ..., -10500.,  -6627.,   -732.],\n       dtype=float32),\n array([ 3594.,  4394.,  1905., ...,   468.,   -81., -5205.], dtype=float32),\n array([ -7646.,  -1393.,   4052., ...,  -1651.,  -8911., -11260.],\n       dtype=float32),\n array([-11677.,  -9033.,  -3163., ...,  12128.,   6230.,     59.],\n       dtype=float32),\n array([-5400., -8652., -8349., ...,  1481.,  2992.,  3946.], dtype=float32),\n array([ 1853., -2766., -4262., ...,   270., -4178., -8720.], dtype=float32),\n array([-10222.,  -5818.,    706., ...,   -668.,  -2321.,   1097.],\n       dtype=float32),\n array([ 5451.,  4190.,   444., ..., -1711., -2083., -2013.], dtype=float32),\n array([ -736., -1006.,  -496., ...,  1621.,  -281., -1539.], dtype=float32)]"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_split"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Fourier Transformation\n",
    "\n",
    "Transform data into frequency domain."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "from scipy.fftpack import fft, ifft\n",
    "\n",
    "def fourier_trans(sr, data):\n",
    "    df_ftt = []\n",
    "    freq = []\n",
    "\n",
    "    df = pd.DataFrame()\n",
    "    x = 0\n",
    "    for i in data:\n",
    "\n",
    "        length = i.shape[0] / sr\n",
    "        N = i.shape[0]\n",
    "        n = np.arange(N)\n",
    "        freq.append(n/length)\n",
    "        df_i = pd.DataFrame(fft(i).real, columns = [x])\n",
    "        x += 1\n",
    "        df = pd.concat([df,df_i], axis = 1)\n",
    "\n",
    "    return freq, df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "freq, df_fft = fourier_trans(sr[0],df_split)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "                  0            1             2             3           4   \\\n0       19071.000000  5141.000000 -34349.000000  30656.000000 -513.000000   \n1       19093.173828  5289.685547 -34628.261719  30817.953125 -413.034180   \n2       19179.093750  5145.678223 -34629.593750  30692.207031 -176.060547   \n3       19173.091797  5127.064941 -34667.054688  30698.093750 -435.553955   \n4       19182.296875  5288.978027 -34572.914062  31036.111328 -440.333374   \n...              ...          ...           ...           ...         ...   \n255995  19163.554688  5203.730957 -34699.195312  30716.000000 -449.495117   \n255996  19182.296875  5288.978027 -34572.914062  31036.111328 -440.333374   \n255997  19173.091797  5127.064941 -34667.054688  30698.093750 -435.553955   \n255998  19179.093750  5145.678223 -34629.593750  30692.207031 -176.060547   \n255999  19093.173828  5289.685547 -34628.261719  30817.953125 -413.034180   \n\n                5            6             7            8             9   \\\n0       400.000000  6398.000000 -13034.000000 -2897.000000  10212.000000   \n1        64.886475  6539.176270 -13122.257812 -2647.667480   9989.706055   \n2       178.049683  6742.463379 -13324.482422 -2718.546631   9983.959961   \n3       183.742432  6510.910156 -13017.246094 -2506.540283   9847.266602   \n4        40.684326  6677.865234 -13349.007812 -2702.960693  10116.700195   \n...            ...          ...           ...          ...           ...   \n255995  -31.591675  6546.589844 -13111.677734 -2414.358643   9955.338867   \n255996   40.684326  6677.865234 -13349.007812 -2702.960693  10116.700195   \n255997  183.742432  6510.910156 -13017.246094 -2506.540283   9847.266602   \n255998  178.049683  6742.463379 -13324.482422 -2718.546631   9983.959961   \n255999   64.886475  6539.176270 -13122.257812 -2647.667480   9989.706055   \n\n                 10            11            12           13            14  \\\n0      -6592.000000 -17912.000000  12722.000000  4212.000000  15227.000000   \n1      -6497.345703 -17600.183594  12712.310547  4167.133789  14837.760742   \n2      -6435.954102 -17571.748047  12555.228516  4434.281738  14993.858398   \n3      -6505.699707 -17642.421875  12548.259766  4069.319336  14923.116211   \n4      -6490.904785 -17750.703125  12493.661133  4237.856445  14874.955078   \n...             ...           ...           ...          ...           ...   \n255995 -6700.813965 -17680.121094  12668.232422  4188.962402  14875.952148   \n255996 -6490.904785 -17750.703125  12493.661133  4237.856445  14874.955078   \n255997 -6505.699707 -17642.421875  12548.259766  4069.319336  14923.116211   \n255998 -6435.954102 -17571.748047  12555.228516  4434.281738  14993.858398   \n255999 -6497.345703 -17600.183594  12712.310547  4167.133789  14837.760742   \n\n                  15           16           17           18           19  \n0      -12504.000000 -1985.000000 -7202.000000  2426.000000  8777.000000  \n1      -12682.062500 -2049.658203 -7411.288574  2688.912109  8872.757812  \n2      -12747.450195 -1977.096191 -7124.540039  2788.823730  8841.103516  \n3      -12627.946289 -1995.334473 -7709.329590  2638.404053  8760.528320  \n4      -12823.578125 -1973.034668 -7233.260254  2538.644287  8717.990234  \n...              ...          ...          ...          ...          ...  \n255995 -12666.001953 -1929.237305 -7553.932129  2474.891113  8710.720703  \n255996 -12823.578125 -1973.034668 -7233.260254  2538.644287  8717.990234  \n255997 -12627.946289 -1995.334473 -7709.329590  2638.404053  8760.528320  \n255998 -12747.450195 -1977.096191 -7124.540039  2788.823730  8841.103516  \n255999 -12682.062500 -2049.658203 -7411.288574  2688.912109  8872.757812  \n\n[256000 rows x 20 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>10</th>\n      <th>11</th>\n      <th>12</th>\n      <th>13</th>\n      <th>14</th>\n      <th>15</th>\n      <th>16</th>\n      <th>17</th>\n      <th>18</th>\n      <th>19</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>19071.000000</td>\n      <td>5141.000000</td>\n      <td>-34349.000000</td>\n      <td>30656.000000</td>\n      <td>-513.000000</td>\n      <td>400.000000</td>\n      <td>6398.000000</td>\n      <td>-13034.000000</td>\n      <td>-2897.000000</td>\n      <td>10212.000000</td>\n      <td>-6592.000000</td>\n      <td>-17912.000000</td>\n      <td>12722.000000</td>\n      <td>4212.000000</td>\n      <td>15227.000000</td>\n      <td>-12504.000000</td>\n      <td>-1985.000000</td>\n      <td>-7202.000000</td>\n      <td>2426.000000</td>\n      <td>8777.000000</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>19093.173828</td>\n      <td>5289.685547</td>\n      <td>-34628.261719</td>\n      <td>30817.953125</td>\n      <td>-413.034180</td>\n      <td>64.886475</td>\n      <td>6539.176270</td>\n      <td>-13122.257812</td>\n      <td>-2647.667480</td>\n      <td>9989.706055</td>\n      <td>-6497.345703</td>\n      <td>-17600.183594</td>\n      <td>12712.310547</td>\n      <td>4167.133789</td>\n      <td>14837.760742</td>\n      <td>-12682.062500</td>\n      <td>-2049.658203</td>\n      <td>-7411.288574</td>\n      <td>2688.912109</td>\n      <td>8872.757812</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>19179.093750</td>\n      <td>5145.678223</td>\n      <td>-34629.593750</td>\n      <td>30692.207031</td>\n      <td>-176.060547</td>\n      <td>178.049683</td>\n      <td>6742.463379</td>\n      <td>-13324.482422</td>\n      <td>-2718.546631</td>\n      <td>9983.959961</td>\n      <td>-6435.954102</td>\n      <td>-17571.748047</td>\n      <td>12555.228516</td>\n      <td>4434.281738</td>\n      <td>14993.858398</td>\n      <td>-12747.450195</td>\n      <td>-1977.096191</td>\n      <td>-7124.540039</td>\n      <td>2788.823730</td>\n      <td>8841.103516</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>19173.091797</td>\n      <td>5127.064941</td>\n      <td>-34667.054688</td>\n      <td>30698.093750</td>\n      <td>-435.553955</td>\n      <td>183.742432</td>\n      <td>6510.910156</td>\n      <td>-13017.246094</td>\n      <td>-2506.540283</td>\n      <td>9847.266602</td>\n      <td>-6505.699707</td>\n      <td>-17642.421875</td>\n      <td>12548.259766</td>\n      <td>4069.319336</td>\n      <td>14923.116211</td>\n      <td>-12627.946289</td>\n      <td>-1995.334473</td>\n      <td>-7709.329590</td>\n      <td>2638.404053</td>\n      <td>8760.528320</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>19182.296875</td>\n      <td>5288.978027</td>\n      <td>-34572.914062</td>\n      <td>31036.111328</td>\n      <td>-440.333374</td>\n      <td>40.684326</td>\n      <td>6677.865234</td>\n      <td>-13349.007812</td>\n      <td>-2702.960693</td>\n      <td>10116.700195</td>\n      <td>-6490.904785</td>\n      <td>-17750.703125</td>\n      <td>12493.661133</td>\n      <td>4237.856445</td>\n      <td>14874.955078</td>\n      <td>-12823.578125</td>\n      <td>-1973.034668</td>\n      <td>-7233.260254</td>\n      <td>2538.644287</td>\n      <td>8717.990234</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>255995</th>\n      <td>19163.554688</td>\n      <td>5203.730957</td>\n      <td>-34699.195312</td>\n      <td>30716.000000</td>\n      <td>-449.495117</td>\n      <td>-31.591675</td>\n      <td>6546.589844</td>\n      <td>-13111.677734</td>\n      <td>-2414.358643</td>\n      <td>9955.338867</td>\n      <td>-6700.813965</td>\n      <td>-17680.121094</td>\n      <td>12668.232422</td>\n      <td>4188.962402</td>\n      <td>14875.952148</td>\n      <td>-12666.001953</td>\n      <td>-1929.237305</td>\n      <td>-7553.932129</td>\n      <td>2474.891113</td>\n      <td>8710.720703</td>\n    </tr>\n    <tr>\n      <th>255996</th>\n      <td>19182.296875</td>\n      <td>5288.978027</td>\n      <td>-34572.914062</td>\n      <td>31036.111328</td>\n      <td>-440.333374</td>\n      <td>40.684326</td>\n      <td>6677.865234</td>\n      <td>-13349.007812</td>\n      <td>-2702.960693</td>\n      <td>10116.700195</td>\n      <td>-6490.904785</td>\n      <td>-17750.703125</td>\n      <td>12493.661133</td>\n      <td>4237.856445</td>\n      <td>14874.955078</td>\n      <td>-12823.578125</td>\n      <td>-1973.034668</td>\n      <td>-7233.260254</td>\n      <td>2538.644287</td>\n      <td>8717.990234</td>\n    </tr>\n    <tr>\n      <th>255997</th>\n      <td>19173.091797</td>\n      <td>5127.064941</td>\n      <td>-34667.054688</td>\n      <td>30698.093750</td>\n      <td>-435.553955</td>\n      <td>183.742432</td>\n      <td>6510.910156</td>\n      <td>-13017.246094</td>\n      <td>-2506.540283</td>\n      <td>9847.266602</td>\n      <td>-6505.699707</td>\n      <td>-17642.421875</td>\n      <td>12548.259766</td>\n      <td>4069.319336</td>\n      <td>14923.116211</td>\n      <td>-12627.946289</td>\n      <td>-1995.334473</td>\n      <td>-7709.329590</td>\n      <td>2638.404053</td>\n      <td>8760.528320</td>\n    </tr>\n    <tr>\n      <th>255998</th>\n      <td>19179.093750</td>\n      <td>5145.678223</td>\n      <td>-34629.593750</td>\n      <td>30692.207031</td>\n      <td>-176.060547</td>\n      <td>178.049683</td>\n      <td>6742.463379</td>\n      <td>-13324.482422</td>\n      <td>-2718.546631</td>\n      <td>9983.959961</td>\n      <td>-6435.954102</td>\n      <td>-17571.748047</td>\n      <td>12555.228516</td>\n      <td>4434.281738</td>\n      <td>14993.858398</td>\n      <td>-12747.450195</td>\n      <td>-1977.096191</td>\n      <td>-7124.540039</td>\n      <td>2788.823730</td>\n      <td>8841.103516</td>\n    </tr>\n    <tr>\n      <th>255999</th>\n      <td>19093.173828</td>\n      <td>5289.685547</td>\n      <td>-34628.261719</td>\n      <td>30817.953125</td>\n      <td>-413.034180</td>\n      <td>64.886475</td>\n      <td>6539.176270</td>\n      <td>-13122.257812</td>\n      <td>-2647.667480</td>\n      <td>9989.706055</td>\n      <td>-6497.345703</td>\n      <td>-17600.183594</td>\n      <td>12712.310547</td>\n      <td>4167.133789</td>\n      <td>14837.760742</td>\n      <td>-12682.062500</td>\n      <td>-2049.658203</td>\n      <td>-7411.288574</td>\n      <td>2688.912109</td>\n      <td>8872.757812</td>\n    </tr>\n  </tbody>\n</table>\n<p>256000 rows Ã— 20 columns</p>\n</div>"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_fft"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "def plot_whole_freq(frequency, spectrum):\n",
    "\n",
    "    plt.figure(figsize = (12, 6))\n",
    "    plt.subplot(121)\n",
    "\n",
    "    plt.stem(frequency[1], np.abs(spectrum), 'b', \\\n",
    "             markerfmt=\" \", basefmt=\"-b\")\n",
    "    plt.xlabel('Freq (Hz)')\n",
    "    plt.ylabel('FFT Amplitude |X(freq)|')\n",
    "\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 1200x600 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_whole_freq(freq,df_fft[0])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 500x500 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_half_freq(frequency, spectrum):\n",
    "\n",
    "    X = np.fft.fft(spectrum)\n",
    "    X_mag = np.abs(X)\n",
    "    f = np.linspace(0, sr[0], len(X_mag))\n",
    "    half = int(len(X_mag)/2)\n",
    "    fft_fre = np.fft.rfftfreq(len(X_mag), d=1./frequency)\n",
    "\n",
    "    abs_spec = abs(X_mag[:half+1])\n",
    "    plt.figure(figsize=(5, 5))\n",
    "    plt.plot(fft_fre, abs_spec) # magnitude spectrum\n",
    "    plt.xlabel('Frequency (Hz)')\n",
    "    plt.show()\n",
    "\n",
    "plot_half_freq(sr[0],df_fft[0])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Feature extraction and labels\n",
    "\n",
    "Extract statistical features and add a label."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "import os\n",
    "import scipy.io as scio\n",
    "from scipy.stats import norm, kurtosis, skew\n",
    "import pandas as pd\n",
    "import math\n",
    "import csv\n",
    "'''\n",
    "1. Central Trend Statistics:\n",
    "   --- mean\n",
    "   --- median\n",
    "   --- low quartile\n",
    "   --- upper quartile\n",
    "2. Dispersion Degree Statistics:\n",
    "   --- minimum\n",
    "   --- maximum\n",
    "   --- inter quartile range\n",
    "   --- standard deviation\n",
    "   --- root mean square\n",
    "   --- square root amplitude\n",
    "3. Distribution Shape Statistics\n",
    "   --- kurtosis\n",
    "   --- skewness\n",
    "   --- shape factor\n",
    "   --- clearance shape\n",
    "   --- crest factor\n",
    "'''\n",
    "\n",
    "\n",
    "def feature_extraction(df, label):\n",
    "    column_name = [\"mean\", \"median\", \"quartile_25\", \"quartile_75\", \"Max\", \"Min\", \"quartile\", \"std\", \"rms\", \"sra\", \"ff\", \"clf\", \"cf\", \"kurtosis\", \"skew\"]\n",
    "    df_features = pd.DataFrame(columns = column_name) #\n",
    "\n",
    "    for column in df:\n",
    "        feature_list = []\n",
    "\n",
    "           # central trend statistics\n",
    "        data_mean = np.mean(df[column])\n",
    "        data_median = np.median(df[column])\n",
    "        data_quartile_025 = np.quantile(df[column], 0.25)\n",
    "        data_quartile_075 = np.quantile(df[column], 0.75)\n",
    "\n",
    "           # dispersion degree statistics\n",
    "        data_Minimum = np.min(df[column])\n",
    "        data_Maximum = np.max(df[column])\n",
    "        data_quartile = data_quartile_075 - data_quartile_025\n",
    "        data_std = np.std(df[column])\n",
    "        data_rms = np.sqrt((np.mean(df[column]**2)))\n",
    "        data_sra = (np.sum(np.sqrt(np.abs(df[column])))/len(df[column]))**2\n",
    "\n",
    "           # distribution shape statistics\n",
    "        data_kurtosis = kurtosis(df[column])\n",
    "        data_skew = skew(df[column])\n",
    "\n",
    "        data_avg = np.mean(np.abs(df[column]))\n",
    "        data_ff = data_rms / data_avg\n",
    "\n",
    "        data_clf = np.max(np.abs(df[column])) / data_sra\n",
    "        data_cf = np.max(np.abs(df[column])) / data_rms\n",
    "\n",
    "        feature_list = [data_mean, data_median, data_quartile_025, data_quartile_075, data_Maximum, data_Minimum, data_quartile, data_std, data_rms, data_sra, data_ff, data_clf, data_cf , data_kurtosis, data_skew]\n",
    "        feature_list = pd.DataFrame(data=feature_list).T #,\n",
    "        feature_list.columns = column_name\n",
    "\n",
    "        df_features = pd.concat([df_features,feature_list])\n",
    "\n",
    "    if label == \"Cavitation\":\n",
    "        df_features[\"Cavitation\"] = 1\n",
    "\n",
    "    if label == \"No Cavitation\":\n",
    "        df_features[\"Cavitation\"] = 0\n",
    "\n",
    "    if label != \"No Cavitation\" and label != \"Cavitation\":\n",
    "        df_features[\"Cavitation\"] = label\n",
    "    return df_features\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "                  0            1             2             3           4   \\\n0       19071.000000  5141.000000 -34349.000000  30656.000000 -513.000000   \n1       19093.173828  5289.685547 -34628.261719  30817.953125 -413.034180   \n2       19179.093750  5145.678223 -34629.593750  30692.207031 -176.060547   \n3       19173.091797  5127.064941 -34667.054688  30698.093750 -435.553955   \n4       19182.296875  5288.978027 -34572.914062  31036.111328 -440.333374   \n...              ...          ...           ...           ...         ...   \n255995  19163.554688  5203.730957 -34699.195312  30716.000000 -449.495117   \n255996  19182.296875  5288.978027 -34572.914062  31036.111328 -440.333374   \n255997  19173.091797  5127.064941 -34667.054688  30698.093750 -435.553955   \n255998  19179.093750  5145.678223 -34629.593750  30692.207031 -176.060547   \n255999  19093.173828  5289.685547 -34628.261719  30817.953125 -413.034180   \n\n                5            6             7            8             9   \\\n0       400.000000  6398.000000 -13034.000000 -2897.000000  10212.000000   \n1        64.886475  6539.176270 -13122.257812 -2647.667480   9989.706055   \n2       178.049683  6742.463379 -13324.482422 -2718.546631   9983.959961   \n3       183.742432  6510.910156 -13017.246094 -2506.540283   9847.266602   \n4        40.684326  6677.865234 -13349.007812 -2702.960693  10116.700195   \n...            ...          ...           ...          ...           ...   \n255995  -31.591675  6546.589844 -13111.677734 -2414.358643   9955.338867   \n255996   40.684326  6677.865234 -13349.007812 -2702.960693  10116.700195   \n255997  183.742432  6510.910156 -13017.246094 -2506.540283   9847.266602   \n255998  178.049683  6742.463379 -13324.482422 -2718.546631   9983.959961   \n255999   64.886475  6539.176270 -13122.257812 -2647.667480   9989.706055   \n\n                 10            11            12           13            14  \\\n0      -6592.000000 -17912.000000  12722.000000  4212.000000  15227.000000   \n1      -6497.345703 -17600.183594  12712.310547  4167.133789  14837.760742   \n2      -6435.954102 -17571.748047  12555.228516  4434.281738  14993.858398   \n3      -6505.699707 -17642.421875  12548.259766  4069.319336  14923.116211   \n4      -6490.904785 -17750.703125  12493.661133  4237.856445  14874.955078   \n...             ...           ...           ...          ...           ...   \n255995 -6700.813965 -17680.121094  12668.232422  4188.962402  14875.952148   \n255996 -6490.904785 -17750.703125  12493.661133  4237.856445  14874.955078   \n255997 -6505.699707 -17642.421875  12548.259766  4069.319336  14923.116211   \n255998 -6435.954102 -17571.748047  12555.228516  4434.281738  14993.858398   \n255999 -6497.345703 -17600.183594  12712.310547  4167.133789  14837.760742   \n\n                  15           16           17           18           19  \n0      -12504.000000 -1985.000000 -7202.000000  2426.000000  8777.000000  \n1      -12682.062500 -2049.658203 -7411.288574  2688.912109  8872.757812  \n2      -12747.450195 -1977.096191 -7124.540039  2788.823730  8841.103516  \n3      -12627.946289 -1995.334473 -7709.329590  2638.404053  8760.528320  \n4      -12823.578125 -1973.034668 -7233.260254  2538.644287  8717.990234  \n...              ...          ...          ...          ...          ...  \n255995 -12666.001953 -1929.237305 -7553.932129  2474.891113  8710.720703  \n255996 -12823.578125 -1973.034668 -7233.260254  2538.644287  8717.990234  \n255997 -12627.946289 -1995.334473 -7709.329590  2638.404053  8760.528320  \n255998 -12747.450195 -1977.096191 -7124.540039  2788.823730  8841.103516  \n255999 -12682.062500 -2049.658203 -7411.288574  2688.912109  8872.757812  \n\n[256000 rows x 20 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>10</th>\n      <th>11</th>\n      <th>12</th>\n      <th>13</th>\n      <th>14</th>\n      <th>15</th>\n      <th>16</th>\n      <th>17</th>\n      <th>18</th>\n      <th>19</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>19071.000000</td>\n      <td>5141.000000</td>\n      <td>-34349.000000</td>\n      <td>30656.000000</td>\n      <td>-513.000000</td>\n      <td>400.000000</td>\n      <td>6398.000000</td>\n      <td>-13034.000000</td>\n      <td>-2897.000000</td>\n      <td>10212.000000</td>\n      <td>-6592.000000</td>\n      <td>-17912.000000</td>\n      <td>12722.000000</td>\n      <td>4212.000000</td>\n      <td>15227.000000</td>\n      <td>-12504.000000</td>\n      <td>-1985.000000</td>\n      <td>-7202.000000</td>\n      <td>2426.000000</td>\n      <td>8777.000000</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>19093.173828</td>\n      <td>5289.685547</td>\n      <td>-34628.261719</td>\n      <td>30817.953125</td>\n      <td>-413.034180</td>\n      <td>64.886475</td>\n      <td>6539.176270</td>\n      <td>-13122.257812</td>\n      <td>-2647.667480</td>\n      <td>9989.706055</td>\n      <td>-6497.345703</td>\n      <td>-17600.183594</td>\n      <td>12712.310547</td>\n      <td>4167.133789</td>\n      <td>14837.760742</td>\n      <td>-12682.062500</td>\n      <td>-2049.658203</td>\n      <td>-7411.288574</td>\n      <td>2688.912109</td>\n      <td>8872.757812</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>19179.093750</td>\n      <td>5145.678223</td>\n      <td>-34629.593750</td>\n      <td>30692.207031</td>\n      <td>-176.060547</td>\n      <td>178.049683</td>\n      <td>6742.463379</td>\n      <td>-13324.482422</td>\n      <td>-2718.546631</td>\n      <td>9983.959961</td>\n      <td>-6435.954102</td>\n      <td>-17571.748047</td>\n      <td>12555.228516</td>\n      <td>4434.281738</td>\n      <td>14993.858398</td>\n      <td>-12747.450195</td>\n      <td>-1977.096191</td>\n      <td>-7124.540039</td>\n      <td>2788.823730</td>\n      <td>8841.103516</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>19173.091797</td>\n      <td>5127.064941</td>\n      <td>-34667.054688</td>\n      <td>30698.093750</td>\n      <td>-435.553955</td>\n      <td>183.742432</td>\n      <td>6510.910156</td>\n      <td>-13017.246094</td>\n      <td>-2506.540283</td>\n      <td>9847.266602</td>\n      <td>-6505.699707</td>\n      <td>-17642.421875</td>\n      <td>12548.259766</td>\n      <td>4069.319336</td>\n      <td>14923.116211</td>\n      <td>-12627.946289</td>\n      <td>-1995.334473</td>\n      <td>-7709.329590</td>\n      <td>2638.404053</td>\n      <td>8760.528320</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>19182.296875</td>\n      <td>5288.978027</td>\n      <td>-34572.914062</td>\n      <td>31036.111328</td>\n      <td>-440.333374</td>\n      <td>40.684326</td>\n      <td>6677.865234</td>\n      <td>-13349.007812</td>\n      <td>-2702.960693</td>\n      <td>10116.700195</td>\n      <td>-6490.904785</td>\n      <td>-17750.703125</td>\n      <td>12493.661133</td>\n      <td>4237.856445</td>\n      <td>14874.955078</td>\n      <td>-12823.578125</td>\n      <td>-1973.034668</td>\n      <td>-7233.260254</td>\n      <td>2538.644287</td>\n      <td>8717.990234</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>255995</th>\n      <td>19163.554688</td>\n      <td>5203.730957</td>\n      <td>-34699.195312</td>\n      <td>30716.000000</td>\n      <td>-449.495117</td>\n      <td>-31.591675</td>\n      <td>6546.589844</td>\n      <td>-13111.677734</td>\n      <td>-2414.358643</td>\n      <td>9955.338867</td>\n      <td>-6700.813965</td>\n      <td>-17680.121094</td>\n      <td>12668.232422</td>\n      <td>4188.962402</td>\n      <td>14875.952148</td>\n      <td>-12666.001953</td>\n      <td>-1929.237305</td>\n      <td>-7553.932129</td>\n      <td>2474.891113</td>\n      <td>8710.720703</td>\n    </tr>\n    <tr>\n      <th>255996</th>\n      <td>19182.296875</td>\n      <td>5288.978027</td>\n      <td>-34572.914062</td>\n      <td>31036.111328</td>\n      <td>-440.333374</td>\n      <td>40.684326</td>\n      <td>6677.865234</td>\n      <td>-13349.007812</td>\n      <td>-2702.960693</td>\n      <td>10116.700195</td>\n      <td>-6490.904785</td>\n      <td>-17750.703125</td>\n      <td>12493.661133</td>\n      <td>4237.856445</td>\n      <td>14874.955078</td>\n      <td>-12823.578125</td>\n      <td>-1973.034668</td>\n      <td>-7233.260254</td>\n      <td>2538.644287</td>\n      <td>8717.990234</td>\n    </tr>\n    <tr>\n      <th>255997</th>\n      <td>19173.091797</td>\n      <td>5127.064941</td>\n      <td>-34667.054688</td>\n      <td>30698.093750</td>\n      <td>-435.553955</td>\n      <td>183.742432</td>\n      <td>6510.910156</td>\n      <td>-13017.246094</td>\n      <td>-2506.540283</td>\n      <td>9847.266602</td>\n      <td>-6505.699707</td>\n      <td>-17642.421875</td>\n      <td>12548.259766</td>\n      <td>4069.319336</td>\n      <td>14923.116211</td>\n      <td>-12627.946289</td>\n      <td>-1995.334473</td>\n      <td>-7709.329590</td>\n      <td>2638.404053</td>\n      <td>8760.528320</td>\n    </tr>\n    <tr>\n      <th>255998</th>\n      <td>19179.093750</td>\n      <td>5145.678223</td>\n      <td>-34629.593750</td>\n      <td>30692.207031</td>\n      <td>-176.060547</td>\n      <td>178.049683</td>\n      <td>6742.463379</td>\n      <td>-13324.482422</td>\n      <td>-2718.546631</td>\n      <td>9983.959961</td>\n      <td>-6435.954102</td>\n      <td>-17571.748047</td>\n      <td>12555.228516</td>\n      <td>4434.281738</td>\n      <td>14993.858398</td>\n      <td>-12747.450195</td>\n      <td>-1977.096191</td>\n      <td>-7124.540039</td>\n      <td>2788.823730</td>\n      <td>8841.103516</td>\n    </tr>\n    <tr>\n      <th>255999</th>\n      <td>19093.173828</td>\n      <td>5289.685547</td>\n      <td>-34628.261719</td>\n      <td>30817.953125</td>\n      <td>-413.034180</td>\n      <td>64.886475</td>\n      <td>6539.176270</td>\n      <td>-13122.257812</td>\n      <td>-2647.667480</td>\n      <td>9989.706055</td>\n      <td>-6497.345703</td>\n      <td>-17600.183594</td>\n      <td>12712.310547</td>\n      <td>4167.133789</td>\n      <td>14837.760742</td>\n      <td>-12682.062500</td>\n      <td>-2049.658203</td>\n      <td>-7411.288574</td>\n      <td>2688.912109</td>\n      <td>8872.757812</td>\n    </tr>\n  </tbody>\n</table>\n<p>256000 rows Ã— 20 columns</p>\n</div>"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_fft"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "data_std = np.std(df_fft[0])\n",
    "\n",
    "data_rms = np.sqrt((np.mean(df_fft[0]**2)))\n",
    "data_sra = (np.sum(np.sqrt(np.abs(df_fft[0])))/len(df_fft[0]))**2"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "h_c_df = feature_extraction(df_fft, \"Cavitation\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "data": {
      "text/plain": "           mean       median    quartile_25    quartile_75         Max  \\\n0    132.999939  5125.717773 -186619.554688  188098.558594  22628324.0   \n0   -221.999054  4317.141113 -191900.425781  187638.832031  18148844.0   \n0  -7008.000977 -9464.326172 -198913.824219  188372.183594  18738612.0   \n0   7773.000000  6992.319824 -186983.222656  200796.222656  18166504.0   \n0  -7246.000488  -823.357422 -209214.546875  188527.863281  19387884.0   \n0   1553.000732  2075.617676 -202292.375000  204708.347656  24401804.0   \n0  -3872.999512  4568.797852 -207491.605469  203715.601562  18801876.0   \n0 -10082.000000 -5638.640625 -216123.625000  202159.488281  23960292.0   \n0  -1555.000488  2597.000000 -202072.023438  214055.171875  20609756.0   \n0  -6543.000000 -7463.250000 -213624.144531  201410.031250  24332520.0   \n0   7411.000000  4631.888672 -204069.328125  214447.386719  21495016.0   \n0  -2106.999268 -3808.749756 -210823.820312  204255.023438  27346286.0   \n0   3593.999756  8366.222656 -201625.722656  210749.402344  21706130.0   \n0  -7645.998047  2498.367676 -209774.968750  203598.757812  20451036.0   \n0 -11676.998047 -3047.265625 -216341.558594  199429.820312  21108718.0   \n0  -5399.999512 -4674.824219 -215192.789062  203490.335938  20333708.0   \n0   1853.000366  5834.000000 -204767.660156  220689.300781  20530716.0   \n0 -10221.999023 -7392.396484 -220528.042969  201759.277344  21356968.0   \n0   5451.000000  2641.799805 -201213.632812  212511.175781  19764536.0   \n0   -735.998901  3732.281250 -200783.386719  194651.062500  20438080.0   \n\n          Min       quartile          std          rms            sra  \\\n0 -16473818.0  374718.113281  1338048.375  1338048.375  332413.794224   \n0 -18371788.0  379539.257812  1373984.750  1373984.750  332235.302852   \n0 -17057312.0  387286.007812  1390564.000  1390581.625  349908.628196   \n0 -18051740.0  387779.445312  1390756.375  1390778.000  347284.950154   \n0 -17455274.0  397742.410156  1451683.750  1451701.750  340991.179080   \n0 -19217512.0  407000.722656  1569998.750  1569999.375  352554.054847   \n0 -23249420.0  411207.207031  1573524.750  1573529.375  358708.310737   \n0 -20217122.0  418283.113281  1586034.500  1586066.625  369328.764038   \n0 -23046816.0  416127.195312  1611870.250  1611871.000  364817.736502   \n0 -21321304.0  415034.175781  1604092.125  1604105.375  372015.062348   \n0 -23663412.0  418516.714844  1587421.375  1587438.625  367874.471018   \n0 -23823274.0  415078.843750  1568304.750  1568306.125  366388.922288   \n0 -21584808.0  412375.125000  1572405.875  1572409.875  366728.196166   \n0 -20565104.0  413373.726562  1570652.375  1570670.875  361141.127856   \n0 -19887192.0  415771.378906  1572084.750  1572128.125  370081.813992   \n0 -19361384.0  418683.125000  1578421.375  1578430.625  367818.445260   \n0 -29124400.0  425456.960938  1595624.750  1595625.750  368613.667144   \n0 -18748084.0  422287.320312  1579480.875  1579514.000  370719.175906   \n0 -33838072.0  413724.808594  1580165.875  1580175.125  360252.569284   \n0 -19650650.0  395434.449219  1442635.250  1442635.375  344631.078046   \n\n         ff        clf         cf   kurtosis      skew  Cavitation  \n0  2.150615  68.072759  16.911440  20.642856  0.042880           1  \n0  2.154837  55.297519  13.371173  19.862270 -0.018263           1  \n0  2.146276  53.552872  13.475377  19.875391  0.049199           1  \n0  2.148971  52.310081  13.062117  20.148841 -0.005838           1  \n0  2.187088  56.857436  13.355281  21.403290  0.100190           1  \n0  2.251016  69.214362  15.542557  23.623902  0.008836           1  \n0  2.247218  64.814278  14.775332  23.515066 -0.098629           1  \n0  2.230877  64.875239  15.106737  23.173603 -0.128512           1  \n0  2.248344  63.173507  14.298177  23.598104 -0.253124           1  \n0  2.252881  65.407352  15.168903  24.711052 -0.078195           1  \n0  2.240004  64.324692  14.906663  24.580768 -0.063267           1  \n0  2.222203  74.637317  17.436829  23.214322  0.043535           1  \n0  2.230668  59.188604  13.804372  23.166445 -0.002690           1  \n0  2.217430  56.944785  13.093198  21.960636 -0.215193           1  \n0  2.219083  57.037977  13.426844  22.462923  0.021200           1  \n0  2.224674  55.281915  12.882231  22.662410  0.017587           1  \n0  2.231922  79.010635  18.252651  24.029214 -0.190509           1  \n0  2.219824  57.609558  13.521228  21.959184  0.154930           1  \n0  2.235467  93.928746  21.414127  25.201136 -0.182571           1  \n0  2.183255  59.304228  14.167184  21.545543 -0.119780           1  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>mean</th>\n      <th>median</th>\n      <th>quartile_25</th>\n      <th>quartile_75</th>\n      <th>Max</th>\n      <th>Min</th>\n      <th>quartile</th>\n      <th>std</th>\n      <th>rms</th>\n      <th>sra</th>\n      <th>ff</th>\n      <th>clf</th>\n      <th>cf</th>\n      <th>kurtosis</th>\n      <th>skew</th>\n      <th>Cavitation</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>132.999939</td>\n      <td>5125.717773</td>\n      <td>-186619.554688</td>\n      <td>188098.558594</td>\n      <td>22628324.0</td>\n      <td>-16473818.0</td>\n      <td>374718.113281</td>\n      <td>1338048.375</td>\n      <td>1338048.375</td>\n      <td>332413.794224</td>\n      <td>2.150615</td>\n      <td>68.072759</td>\n      <td>16.911440</td>\n      <td>20.642856</td>\n      <td>0.042880</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>-221.999054</td>\n      <td>4317.141113</td>\n      <td>-191900.425781</td>\n      <td>187638.832031</td>\n      <td>18148844.0</td>\n      <td>-18371788.0</td>\n      <td>379539.257812</td>\n      <td>1373984.750</td>\n      <td>1373984.750</td>\n      <td>332235.302852</td>\n      <td>2.154837</td>\n      <td>55.297519</td>\n      <td>13.371173</td>\n      <td>19.862270</td>\n      <td>-0.018263</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>-7008.000977</td>\n      <td>-9464.326172</td>\n      <td>-198913.824219</td>\n      <td>188372.183594</td>\n      <td>18738612.0</td>\n      <td>-17057312.0</td>\n      <td>387286.007812</td>\n      <td>1390564.000</td>\n      <td>1390581.625</td>\n      <td>349908.628196</td>\n      <td>2.146276</td>\n      <td>53.552872</td>\n      <td>13.475377</td>\n      <td>19.875391</td>\n      <td>0.049199</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>7773.000000</td>\n      <td>6992.319824</td>\n      <td>-186983.222656</td>\n      <td>200796.222656</td>\n      <td>18166504.0</td>\n      <td>-18051740.0</td>\n      <td>387779.445312</td>\n      <td>1390756.375</td>\n      <td>1390778.000</td>\n      <td>347284.950154</td>\n      <td>2.148971</td>\n      <td>52.310081</td>\n      <td>13.062117</td>\n      <td>20.148841</td>\n      <td>-0.005838</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>-7246.000488</td>\n      <td>-823.357422</td>\n      <td>-209214.546875</td>\n      <td>188527.863281</td>\n      <td>19387884.0</td>\n      <td>-17455274.0</td>\n      <td>397742.410156</td>\n      <td>1451683.750</td>\n      <td>1451701.750</td>\n      <td>340991.179080</td>\n      <td>2.187088</td>\n      <td>56.857436</td>\n      <td>13.355281</td>\n      <td>21.403290</td>\n      <td>0.100190</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>1553.000732</td>\n      <td>2075.617676</td>\n      <td>-202292.375000</td>\n      <td>204708.347656</td>\n      <td>24401804.0</td>\n      <td>-19217512.0</td>\n      <td>407000.722656</td>\n      <td>1569998.750</td>\n      <td>1569999.375</td>\n      <td>352554.054847</td>\n      <td>2.251016</td>\n      <td>69.214362</td>\n      <td>15.542557</td>\n      <td>23.623902</td>\n      <td>0.008836</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>-3872.999512</td>\n      <td>4568.797852</td>\n      <td>-207491.605469</td>\n      <td>203715.601562</td>\n      <td>18801876.0</td>\n      <td>-23249420.0</td>\n      <td>411207.207031</td>\n      <td>1573524.750</td>\n      <td>1573529.375</td>\n      <td>358708.310737</td>\n      <td>2.247218</td>\n      <td>64.814278</td>\n      <td>14.775332</td>\n      <td>23.515066</td>\n      <td>-0.098629</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>-10082.000000</td>\n      <td>-5638.640625</td>\n      <td>-216123.625000</td>\n      <td>202159.488281</td>\n      <td>23960292.0</td>\n      <td>-20217122.0</td>\n      <td>418283.113281</td>\n      <td>1586034.500</td>\n      <td>1586066.625</td>\n      <td>369328.764038</td>\n      <td>2.230877</td>\n      <td>64.875239</td>\n      <td>15.106737</td>\n      <td>23.173603</td>\n      <td>-0.128512</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>-1555.000488</td>\n      <td>2597.000000</td>\n      <td>-202072.023438</td>\n      <td>214055.171875</td>\n      <td>20609756.0</td>\n      <td>-23046816.0</td>\n      <td>416127.195312</td>\n      <td>1611870.250</td>\n      <td>1611871.000</td>\n      <td>364817.736502</td>\n      <td>2.248344</td>\n      <td>63.173507</td>\n      <td>14.298177</td>\n      <td>23.598104</td>\n      <td>-0.253124</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>-6543.000000</td>\n      <td>-7463.250000</td>\n      <td>-213624.144531</td>\n      <td>201410.031250</td>\n      <td>24332520.0</td>\n      <td>-21321304.0</td>\n      <td>415034.175781</td>\n      <td>1604092.125</td>\n      <td>1604105.375</td>\n      <td>372015.062348</td>\n      <td>2.252881</td>\n      <td>65.407352</td>\n      <td>15.168903</td>\n      <td>24.711052</td>\n      <td>-0.078195</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>7411.000000</td>\n      <td>4631.888672</td>\n      <td>-204069.328125</td>\n      <td>214447.386719</td>\n      <td>21495016.0</td>\n      <td>-23663412.0</td>\n      <td>418516.714844</td>\n      <td>1587421.375</td>\n      <td>1587438.625</td>\n      <td>367874.471018</td>\n      <td>2.240004</td>\n      <td>64.324692</td>\n      <td>14.906663</td>\n      <td>24.580768</td>\n      <td>-0.063267</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>-2106.999268</td>\n      <td>-3808.749756</td>\n      <td>-210823.820312</td>\n      <td>204255.023438</td>\n      <td>27346286.0</td>\n      <td>-23823274.0</td>\n      <td>415078.843750</td>\n      <td>1568304.750</td>\n      <td>1568306.125</td>\n      <td>366388.922288</td>\n      <td>2.222203</td>\n      <td>74.637317</td>\n      <td>17.436829</td>\n      <td>23.214322</td>\n      <td>0.043535</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>3593.999756</td>\n      <td>8366.222656</td>\n      <td>-201625.722656</td>\n      <td>210749.402344</td>\n      <td>21706130.0</td>\n      <td>-21584808.0</td>\n      <td>412375.125000</td>\n      <td>1572405.875</td>\n      <td>1572409.875</td>\n      <td>366728.196166</td>\n      <td>2.230668</td>\n      <td>59.188604</td>\n      <td>13.804372</td>\n      <td>23.166445</td>\n      <td>-0.002690</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>-7645.998047</td>\n      <td>2498.367676</td>\n      <td>-209774.968750</td>\n      <td>203598.757812</td>\n      <td>20451036.0</td>\n      <td>-20565104.0</td>\n      <td>413373.726562</td>\n      <td>1570652.375</td>\n      <td>1570670.875</td>\n      <td>361141.127856</td>\n      <td>2.217430</td>\n      <td>56.944785</td>\n      <td>13.093198</td>\n      <td>21.960636</td>\n      <td>-0.215193</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>-11676.998047</td>\n      <td>-3047.265625</td>\n      <td>-216341.558594</td>\n      <td>199429.820312</td>\n      <td>21108718.0</td>\n      <td>-19887192.0</td>\n      <td>415771.378906</td>\n      <td>1572084.750</td>\n      <td>1572128.125</td>\n      <td>370081.813992</td>\n      <td>2.219083</td>\n      <td>57.037977</td>\n      <td>13.426844</td>\n      <td>22.462923</td>\n      <td>0.021200</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>-5399.999512</td>\n      <td>-4674.824219</td>\n      <td>-215192.789062</td>\n      <td>203490.335938</td>\n      <td>20333708.0</td>\n      <td>-19361384.0</td>\n      <td>418683.125000</td>\n      <td>1578421.375</td>\n      <td>1578430.625</td>\n      <td>367818.445260</td>\n      <td>2.224674</td>\n      <td>55.281915</td>\n      <td>12.882231</td>\n      <td>22.662410</td>\n      <td>0.017587</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>1853.000366</td>\n      <td>5834.000000</td>\n      <td>-204767.660156</td>\n      <td>220689.300781</td>\n      <td>20530716.0</td>\n      <td>-29124400.0</td>\n      <td>425456.960938</td>\n      <td>1595624.750</td>\n      <td>1595625.750</td>\n      <td>368613.667144</td>\n      <td>2.231922</td>\n      <td>79.010635</td>\n      <td>18.252651</td>\n      <td>24.029214</td>\n      <td>-0.190509</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>-10221.999023</td>\n      <td>-7392.396484</td>\n      <td>-220528.042969</td>\n      <td>201759.277344</td>\n      <td>21356968.0</td>\n      <td>-18748084.0</td>\n      <td>422287.320312</td>\n      <td>1579480.875</td>\n      <td>1579514.000</td>\n      <td>370719.175906</td>\n      <td>2.219824</td>\n      <td>57.609558</td>\n      <td>13.521228</td>\n      <td>21.959184</td>\n      <td>0.154930</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>5451.000000</td>\n      <td>2641.799805</td>\n      <td>-201213.632812</td>\n      <td>212511.175781</td>\n      <td>19764536.0</td>\n      <td>-33838072.0</td>\n      <td>413724.808594</td>\n      <td>1580165.875</td>\n      <td>1580175.125</td>\n      <td>360252.569284</td>\n      <td>2.235467</td>\n      <td>93.928746</td>\n      <td>21.414127</td>\n      <td>25.201136</td>\n      <td>-0.182571</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>-735.998901</td>\n      <td>3732.281250</td>\n      <td>-200783.386719</td>\n      <td>194651.062500</td>\n      <td>20438080.0</td>\n      <td>-19650650.0</td>\n      <td>395434.449219</td>\n      <td>1442635.250</td>\n      <td>1442635.375</td>\n      <td>344631.078046</td>\n      <td>2.183255</td>\n      <td>59.304228</td>\n      <td>14.167184</td>\n      <td>21.545543</td>\n      <td>-0.119780</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h_c_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Same procedure for non-cavitation data."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Load file"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kinos\\AppData\\Local\\Temp\\ipykernel_23192\\3207606025.py:6: WavFileWarning: Chunk (non-data) not understood, skipping it.\n",
      "  sf, d = wavfile.read(path/data)\n"
     ]
    }
   ],
   "source": [
    "datasets = [\"sxmany_200206_007_HKMNetzpumpe04_004_RP1_FC_01_C06_SB1_L0_XX_XXXX_YY_YYYY_ZZZZZZ_10.wav\"]\n",
    "\n",
    "sr, df = read_wav(datasets)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Split file"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "df_split = splitting(sr[0],df, 2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Fourier transformation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "freq, df_ftt = fourier_trans(sr[0],df_split)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Feature extraction and add labels"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "n_c_df = feature_extraction(df_ftt, \"No_cavitation\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "data": {
      "text/plain": "         mean      median   quartile_25   quartile_75         Max         Min  \\\n0  188.999969  285.617188 -47249.166992  47166.263672  3911730.00 -3661461.75   \n0  338.999817  442.606445 -50010.841797  50798.194336  3785041.25 -3834865.00   \n0  129.999954  116.105469 -49651.808594  50475.595703  3968321.25 -4272759.00   \n0 -108.000008 -422.437500 -44462.881836  44095.830078  3280548.50 -3466732.00   \n0 -486.000244  778.201172 -56428.169922  54220.079102  5136561.50 -4814440.00   \n0 -243.000031 -893.906250 -54796.658203  55363.051758  4646875.00 -5107823.00   \n0  141.999954  265.414062 -52241.909180  51704.750977  4342194.00 -4544057.50   \n0 -115.999985  736.753906 -53944.679688  54024.585938  4522007.50 -4376049.50   \n0 -369.999878 -646.807617 -45643.958008  44771.317383  4009059.25 -4061546.25   \n0 -294.000122 -497.063477 -51091.940430  50301.433594  4094237.00 -4902808.00   \n\n        quartile           std           rms            sra        ff  \\\n0   94415.430664  344376.28125  344376.34375  100944.548808  1.880099   \n0  100809.036133  378136.12500  378136.31250  108410.954036  1.900190   \n0  100127.404297  380878.37500  380878.37500  108591.544982  1.908602   \n0   88558.711914  325822.90625  325822.93750   93577.199859  1.908470   \n0  110648.249023  444945.62500  444945.84375  125406.308389  1.921647   \n0  110159.709961  411703.87500  411703.93750  120629.272148  1.897077   \n0  103946.660156  403278.59375  403278.59375  113999.587863  1.907325   \n0  107969.265625  395293.18750  395293.18750  114491.338477  1.894048   \n0   90415.275391  347869.31250  347869.53125   98666.054064  1.914248   \n0  101393.374023  385875.12500  385875.21875  111082.286592  1.893865   \n\n         clf         cf   kurtosis      skew     Cavitation  \n0  38.751275  11.358881   8.673351  0.024364  No_cavitation  \n0  35.373409  10.141488   9.288338  0.000133  No_cavitation  \n0  39.347069  11.218172   9.769574 -0.027308  No_cavitation  \n0  37.046759  10.639926   9.994113 -0.015095  No_cavitation  \n0  40.959355  11.544240  10.128421  0.016174  No_cavitation  \n0  42.343147  12.406544  10.025000  0.029561  No_cavitation  \n0  39.860298  11.267788   9.478155  0.014520  No_cavitation  \n0  39.496503  11.439630   9.425841  0.005057  No_cavitation  \n0  41.164576  11.675488   9.878925 -0.009392  No_cavitation  \n0  44.136722  12.705683   9.115134  0.015858  No_cavitation  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>mean</th>\n      <th>median</th>\n      <th>quartile_25</th>\n      <th>quartile_75</th>\n      <th>Max</th>\n      <th>Min</th>\n      <th>quartile</th>\n      <th>std</th>\n      <th>rms</th>\n      <th>sra</th>\n      <th>ff</th>\n      <th>clf</th>\n      <th>cf</th>\n      <th>kurtosis</th>\n      <th>skew</th>\n      <th>Cavitation</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>188.999969</td>\n      <td>285.617188</td>\n      <td>-47249.166992</td>\n      <td>47166.263672</td>\n      <td>3911730.00</td>\n      <td>-3661461.75</td>\n      <td>94415.430664</td>\n      <td>344376.28125</td>\n      <td>344376.34375</td>\n      <td>100944.548808</td>\n      <td>1.880099</td>\n      <td>38.751275</td>\n      <td>11.358881</td>\n      <td>8.673351</td>\n      <td>0.024364</td>\n      <td>No_cavitation</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>338.999817</td>\n      <td>442.606445</td>\n      <td>-50010.841797</td>\n      <td>50798.194336</td>\n      <td>3785041.25</td>\n      <td>-3834865.00</td>\n      <td>100809.036133</td>\n      <td>378136.12500</td>\n      <td>378136.31250</td>\n      <td>108410.954036</td>\n      <td>1.900190</td>\n      <td>35.373409</td>\n      <td>10.141488</td>\n      <td>9.288338</td>\n      <td>0.000133</td>\n      <td>No_cavitation</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>129.999954</td>\n      <td>116.105469</td>\n      <td>-49651.808594</td>\n      <td>50475.595703</td>\n      <td>3968321.25</td>\n      <td>-4272759.00</td>\n      <td>100127.404297</td>\n      <td>380878.37500</td>\n      <td>380878.37500</td>\n      <td>108591.544982</td>\n      <td>1.908602</td>\n      <td>39.347069</td>\n      <td>11.218172</td>\n      <td>9.769574</td>\n      <td>-0.027308</td>\n      <td>No_cavitation</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>-108.000008</td>\n      <td>-422.437500</td>\n      <td>-44462.881836</td>\n      <td>44095.830078</td>\n      <td>3280548.50</td>\n      <td>-3466732.00</td>\n      <td>88558.711914</td>\n      <td>325822.90625</td>\n      <td>325822.93750</td>\n      <td>93577.199859</td>\n      <td>1.908470</td>\n      <td>37.046759</td>\n      <td>10.639926</td>\n      <td>9.994113</td>\n      <td>-0.015095</td>\n      <td>No_cavitation</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>-486.000244</td>\n      <td>778.201172</td>\n      <td>-56428.169922</td>\n      <td>54220.079102</td>\n      <td>5136561.50</td>\n      <td>-4814440.00</td>\n      <td>110648.249023</td>\n      <td>444945.62500</td>\n      <td>444945.84375</td>\n      <td>125406.308389</td>\n      <td>1.921647</td>\n      <td>40.959355</td>\n      <td>11.544240</td>\n      <td>10.128421</td>\n      <td>0.016174</td>\n      <td>No_cavitation</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>-243.000031</td>\n      <td>-893.906250</td>\n      <td>-54796.658203</td>\n      <td>55363.051758</td>\n      <td>4646875.00</td>\n      <td>-5107823.00</td>\n      <td>110159.709961</td>\n      <td>411703.87500</td>\n      <td>411703.93750</td>\n      <td>120629.272148</td>\n      <td>1.897077</td>\n      <td>42.343147</td>\n      <td>12.406544</td>\n      <td>10.025000</td>\n      <td>0.029561</td>\n      <td>No_cavitation</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>141.999954</td>\n      <td>265.414062</td>\n      <td>-52241.909180</td>\n      <td>51704.750977</td>\n      <td>4342194.00</td>\n      <td>-4544057.50</td>\n      <td>103946.660156</td>\n      <td>403278.59375</td>\n      <td>403278.59375</td>\n      <td>113999.587863</td>\n      <td>1.907325</td>\n      <td>39.860298</td>\n      <td>11.267788</td>\n      <td>9.478155</td>\n      <td>0.014520</td>\n      <td>No_cavitation</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>-115.999985</td>\n      <td>736.753906</td>\n      <td>-53944.679688</td>\n      <td>54024.585938</td>\n      <td>4522007.50</td>\n      <td>-4376049.50</td>\n      <td>107969.265625</td>\n      <td>395293.18750</td>\n      <td>395293.18750</td>\n      <td>114491.338477</td>\n      <td>1.894048</td>\n      <td>39.496503</td>\n      <td>11.439630</td>\n      <td>9.425841</td>\n      <td>0.005057</td>\n      <td>No_cavitation</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>-369.999878</td>\n      <td>-646.807617</td>\n      <td>-45643.958008</td>\n      <td>44771.317383</td>\n      <td>4009059.25</td>\n      <td>-4061546.25</td>\n      <td>90415.275391</td>\n      <td>347869.31250</td>\n      <td>347869.53125</td>\n      <td>98666.054064</td>\n      <td>1.914248</td>\n      <td>41.164576</td>\n      <td>11.675488</td>\n      <td>9.878925</td>\n      <td>-0.009392</td>\n      <td>No_cavitation</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>-294.000122</td>\n      <td>-497.063477</td>\n      <td>-51091.940430</td>\n      <td>50301.433594</td>\n      <td>4094237.00</td>\n      <td>-4902808.00</td>\n      <td>101393.374023</td>\n      <td>385875.12500</td>\n      <td>385875.21875</td>\n      <td>111082.286592</td>\n      <td>1.893865</td>\n      <td>44.136722</td>\n      <td>12.705683</td>\n      <td>9.115134</td>\n      <td>0.015858</td>\n      <td>No_cavitation</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_c_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Combine both datasets"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "final_df = pd.concat([h_c_df, n_c_df])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "data": {
      "text/plain": "           mean       median    quartile_25    quartile_75          Max  \\\n0    132.999939  5125.717773 -186619.554688  188098.558594  22628324.00   \n0   -221.999054  4317.141113 -191900.425781  187638.832031  18148844.00   \n0  -7008.000977 -9464.326172 -198913.824219  188372.183594  18738612.00   \n0   7773.000000  6992.319824 -186983.222656  200796.222656  18166504.00   \n0  -7246.000488  -823.357422 -209214.546875  188527.863281  19387884.00   \n0   1553.000732  2075.617676 -202292.375000  204708.347656  24401804.00   \n0  -3872.999512  4568.797852 -207491.605469  203715.601562  18801876.00   \n0 -10082.000000 -5638.640625 -216123.625000  202159.488281  23960292.00   \n0  -1555.000488  2597.000000 -202072.023438  214055.171875  20609756.00   \n0  -6543.000000 -7463.250000 -213624.144531  201410.031250  24332520.00   \n0   7411.000000  4631.888672 -204069.328125  214447.386719  21495016.00   \n0  -2106.999268 -3808.749756 -210823.820312  204255.023438  27346286.00   \n0   3593.999756  8366.222656 -201625.722656  210749.402344  21706130.00   \n0  -7645.998047  2498.367676 -209774.968750  203598.757812  20451036.00   \n0 -11676.998047 -3047.265625 -216341.558594  199429.820312  21108718.00   \n0  -5399.999512 -4674.824219 -215192.789062  203490.335938  20333708.00   \n0   1853.000366  5834.000000 -204767.660156  220689.300781  20530716.00   \n0 -10221.999023 -7392.396484 -220528.042969  201759.277344  21356968.00   \n0   5451.000000  2641.799805 -201213.632812  212511.175781  19764536.00   \n0   -735.998901  3732.281250 -200783.386719  194651.062500  20438080.00   \n0    188.999969   285.617188  -47249.166992   47166.263672   3911730.00   \n0    338.999817   442.606445  -50010.841797   50798.194336   3785041.25   \n0    129.999954   116.105469  -49651.808594   50475.595703   3968321.25   \n0   -108.000008  -422.437500  -44462.881836   44095.830078   3280548.50   \n0   -486.000244   778.201172  -56428.169922   54220.079102   5136561.50   \n0   -243.000031  -893.906250  -54796.658203   55363.051758   4646875.00   \n0    141.999954   265.414062  -52241.909180   51704.750977   4342194.00   \n0   -115.999985   736.753906  -53944.679688   54024.585938   4522007.50   \n0   -369.999878  -646.807617  -45643.958008   44771.317383   4009059.25   \n0   -294.000122  -497.063477  -51091.940430   50301.433594   4094237.00   \n\n           Min       quartile           std           rms            sra  \\\n0 -16473818.00  374718.113281  1.338048e+06  1.338048e+06  332413.794224   \n0 -18371788.00  379539.257812  1.373985e+06  1.373985e+06  332235.302852   \n0 -17057312.00  387286.007812  1.390564e+06  1.390582e+06  349908.628196   \n0 -18051740.00  387779.445312  1.390756e+06  1.390778e+06  347284.950154   \n0 -17455274.00  397742.410156  1.451684e+06  1.451702e+06  340991.179080   \n0 -19217512.00  407000.722656  1.569999e+06  1.569999e+06  352554.054847   \n0 -23249420.00  411207.207031  1.573525e+06  1.573529e+06  358708.310737   \n0 -20217122.00  418283.113281  1.586034e+06  1.586067e+06  369328.764038   \n0 -23046816.00  416127.195312  1.611870e+06  1.611871e+06  364817.736502   \n0 -21321304.00  415034.175781  1.604092e+06  1.604105e+06  372015.062348   \n0 -23663412.00  418516.714844  1.587421e+06  1.587439e+06  367874.471018   \n0 -23823274.00  415078.843750  1.568305e+06  1.568306e+06  366388.922288   \n0 -21584808.00  412375.125000  1.572406e+06  1.572410e+06  366728.196166   \n0 -20565104.00  413373.726562  1.570652e+06  1.570671e+06  361141.127856   \n0 -19887192.00  415771.378906  1.572085e+06  1.572128e+06  370081.813992   \n0 -19361384.00  418683.125000  1.578421e+06  1.578431e+06  367818.445260   \n0 -29124400.00  425456.960938  1.595625e+06  1.595626e+06  368613.667144   \n0 -18748084.00  422287.320312  1.579481e+06  1.579514e+06  370719.175906   \n0 -33838072.00  413724.808594  1.580166e+06  1.580175e+06  360252.569284   \n0 -19650650.00  395434.449219  1.442635e+06  1.442635e+06  344631.078046   \n0  -3661461.75   94415.430664  3.443763e+05  3.443763e+05  100944.548808   \n0  -3834865.00  100809.036133  3.781361e+05  3.781363e+05  108410.954036   \n0  -4272759.00  100127.404297  3.808784e+05  3.808784e+05  108591.544982   \n0  -3466732.00   88558.711914  3.258229e+05  3.258229e+05   93577.199859   \n0  -4814440.00  110648.249023  4.449456e+05  4.449458e+05  125406.308389   \n0  -5107823.00  110159.709961  4.117039e+05  4.117039e+05  120629.272148   \n0  -4544057.50  103946.660156  4.032786e+05  4.032786e+05  113999.587863   \n0  -4376049.50  107969.265625  3.952932e+05  3.952932e+05  114491.338477   \n0  -4061546.25   90415.275391  3.478693e+05  3.478695e+05   98666.054064   \n0  -4902808.00  101393.374023  3.858751e+05  3.858752e+05  111082.286592   \n\n         ff        clf         cf   kurtosis      skew     Cavitation  \n0  2.150615  68.072759  16.911440  20.642856  0.042880              1  \n0  2.154837  55.297519  13.371173  19.862270 -0.018263              1  \n0  2.146276  53.552872  13.475377  19.875391  0.049199              1  \n0  2.148971  52.310081  13.062117  20.148841 -0.005838              1  \n0  2.187088  56.857436  13.355281  21.403290  0.100190              1  \n0  2.251016  69.214362  15.542557  23.623902  0.008836              1  \n0  2.247218  64.814278  14.775332  23.515066 -0.098629              1  \n0  2.230877  64.875239  15.106737  23.173603 -0.128512              1  \n0  2.248344  63.173507  14.298177  23.598104 -0.253124              1  \n0  2.252881  65.407352  15.168903  24.711052 -0.078195              1  \n0  2.240004  64.324692  14.906663  24.580768 -0.063267              1  \n0  2.222203  74.637317  17.436829  23.214322  0.043535              1  \n0  2.230668  59.188604  13.804372  23.166445 -0.002690              1  \n0  2.217430  56.944785  13.093198  21.960636 -0.215193              1  \n0  2.219083  57.037977  13.426844  22.462923  0.021200              1  \n0  2.224674  55.281915  12.882231  22.662410  0.017587              1  \n0  2.231922  79.010635  18.252651  24.029214 -0.190509              1  \n0  2.219824  57.609558  13.521228  21.959184  0.154930              1  \n0  2.235467  93.928746  21.414127  25.201136 -0.182571              1  \n0  2.183255  59.304228  14.167184  21.545543 -0.119780              1  \n0  1.880099  38.751275  11.358881   8.673351  0.024364  No_cavitation  \n0  1.900190  35.373409  10.141488   9.288338  0.000133  No_cavitation  \n0  1.908602  39.347069  11.218172   9.769574 -0.027308  No_cavitation  \n0  1.908470  37.046759  10.639926   9.994113 -0.015095  No_cavitation  \n0  1.921647  40.959355  11.544240  10.128421  0.016174  No_cavitation  \n0  1.897077  42.343147  12.406544  10.025000  0.029561  No_cavitation  \n0  1.907325  39.860298  11.267788   9.478155  0.014520  No_cavitation  \n0  1.894048  39.496503  11.439630   9.425841  0.005057  No_cavitation  \n0  1.914248  41.164576  11.675488   9.878925 -0.009392  No_cavitation  \n0  1.893865  44.136722  12.705683   9.115134  0.015858  No_cavitation  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>mean</th>\n      <th>median</th>\n      <th>quartile_25</th>\n      <th>quartile_75</th>\n      <th>Max</th>\n      <th>Min</th>\n      <th>quartile</th>\n      <th>std</th>\n      <th>rms</th>\n      <th>sra</th>\n      <th>ff</th>\n      <th>clf</th>\n      <th>cf</th>\n      <th>kurtosis</th>\n      <th>skew</th>\n      <th>Cavitation</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>132.999939</td>\n      <td>5125.717773</td>\n      <td>-186619.554688</td>\n      <td>188098.558594</td>\n      <td>22628324.00</td>\n      <td>-16473818.00</td>\n      <td>374718.113281</td>\n      <td>1.338048e+06</td>\n      <td>1.338048e+06</td>\n      <td>332413.794224</td>\n      <td>2.150615</td>\n      <td>68.072759</td>\n      <td>16.911440</td>\n      <td>20.642856</td>\n      <td>0.042880</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>-221.999054</td>\n      <td>4317.141113</td>\n      <td>-191900.425781</td>\n      <td>187638.832031</td>\n      <td>18148844.00</td>\n      <td>-18371788.00</td>\n      <td>379539.257812</td>\n      <td>1.373985e+06</td>\n      <td>1.373985e+06</td>\n      <td>332235.302852</td>\n      <td>2.154837</td>\n      <td>55.297519</td>\n      <td>13.371173</td>\n      <td>19.862270</td>\n      <td>-0.018263</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>-7008.000977</td>\n      <td>-9464.326172</td>\n      <td>-198913.824219</td>\n      <td>188372.183594</td>\n      <td>18738612.00</td>\n      <td>-17057312.00</td>\n      <td>387286.007812</td>\n      <td>1.390564e+06</td>\n      <td>1.390582e+06</td>\n      <td>349908.628196</td>\n      <td>2.146276</td>\n      <td>53.552872</td>\n      <td>13.475377</td>\n      <td>19.875391</td>\n      <td>0.049199</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>7773.000000</td>\n      <td>6992.319824</td>\n      <td>-186983.222656</td>\n      <td>200796.222656</td>\n      <td>18166504.00</td>\n      <td>-18051740.00</td>\n      <td>387779.445312</td>\n      <td>1.390756e+06</td>\n      <td>1.390778e+06</td>\n      <td>347284.950154</td>\n      <td>2.148971</td>\n      <td>52.310081</td>\n      <td>13.062117</td>\n      <td>20.148841</td>\n      <td>-0.005838</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>-7246.000488</td>\n      <td>-823.357422</td>\n      <td>-209214.546875</td>\n      <td>188527.863281</td>\n      <td>19387884.00</td>\n      <td>-17455274.00</td>\n      <td>397742.410156</td>\n      <td>1.451684e+06</td>\n      <td>1.451702e+06</td>\n      <td>340991.179080</td>\n      <td>2.187088</td>\n      <td>56.857436</td>\n      <td>13.355281</td>\n      <td>21.403290</td>\n      <td>0.100190</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>1553.000732</td>\n      <td>2075.617676</td>\n      <td>-202292.375000</td>\n      <td>204708.347656</td>\n      <td>24401804.00</td>\n      <td>-19217512.00</td>\n      <td>407000.722656</td>\n      <td>1.569999e+06</td>\n      <td>1.569999e+06</td>\n      <td>352554.054847</td>\n      <td>2.251016</td>\n      <td>69.214362</td>\n      <td>15.542557</td>\n      <td>23.623902</td>\n      <td>0.008836</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>-3872.999512</td>\n      <td>4568.797852</td>\n      <td>-207491.605469</td>\n      <td>203715.601562</td>\n      <td>18801876.00</td>\n      <td>-23249420.00</td>\n      <td>411207.207031</td>\n      <td>1.573525e+06</td>\n      <td>1.573529e+06</td>\n      <td>358708.310737</td>\n      <td>2.247218</td>\n      <td>64.814278</td>\n      <td>14.775332</td>\n      <td>23.515066</td>\n      <td>-0.098629</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>-10082.000000</td>\n      <td>-5638.640625</td>\n      <td>-216123.625000</td>\n      <td>202159.488281</td>\n      <td>23960292.00</td>\n      <td>-20217122.00</td>\n      <td>418283.113281</td>\n      <td>1.586034e+06</td>\n      <td>1.586067e+06</td>\n      <td>369328.764038</td>\n      <td>2.230877</td>\n      <td>64.875239</td>\n      <td>15.106737</td>\n      <td>23.173603</td>\n      <td>-0.128512</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>-1555.000488</td>\n      <td>2597.000000</td>\n      <td>-202072.023438</td>\n      <td>214055.171875</td>\n      <td>20609756.00</td>\n      <td>-23046816.00</td>\n      <td>416127.195312</td>\n      <td>1.611870e+06</td>\n      <td>1.611871e+06</td>\n      <td>364817.736502</td>\n      <td>2.248344</td>\n      <td>63.173507</td>\n      <td>14.298177</td>\n      <td>23.598104</td>\n      <td>-0.253124</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>-6543.000000</td>\n      <td>-7463.250000</td>\n      <td>-213624.144531</td>\n      <td>201410.031250</td>\n      <td>24332520.00</td>\n      <td>-21321304.00</td>\n      <td>415034.175781</td>\n      <td>1.604092e+06</td>\n      <td>1.604105e+06</td>\n      <td>372015.062348</td>\n      <td>2.252881</td>\n      <td>65.407352</td>\n      <td>15.168903</td>\n      <td>24.711052</td>\n      <td>-0.078195</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>7411.000000</td>\n      <td>4631.888672</td>\n      <td>-204069.328125</td>\n      <td>214447.386719</td>\n      <td>21495016.00</td>\n      <td>-23663412.00</td>\n      <td>418516.714844</td>\n      <td>1.587421e+06</td>\n      <td>1.587439e+06</td>\n      <td>367874.471018</td>\n      <td>2.240004</td>\n      <td>64.324692</td>\n      <td>14.906663</td>\n      <td>24.580768</td>\n      <td>-0.063267</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>-2106.999268</td>\n      <td>-3808.749756</td>\n      <td>-210823.820312</td>\n      <td>204255.023438</td>\n      <td>27346286.00</td>\n      <td>-23823274.00</td>\n      <td>415078.843750</td>\n      <td>1.568305e+06</td>\n      <td>1.568306e+06</td>\n      <td>366388.922288</td>\n      <td>2.222203</td>\n      <td>74.637317</td>\n      <td>17.436829</td>\n      <td>23.214322</td>\n      <td>0.043535</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>3593.999756</td>\n      <td>8366.222656</td>\n      <td>-201625.722656</td>\n      <td>210749.402344</td>\n      <td>21706130.00</td>\n      <td>-21584808.00</td>\n      <td>412375.125000</td>\n      <td>1.572406e+06</td>\n      <td>1.572410e+06</td>\n      <td>366728.196166</td>\n      <td>2.230668</td>\n      <td>59.188604</td>\n      <td>13.804372</td>\n      <td>23.166445</td>\n      <td>-0.002690</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>-7645.998047</td>\n      <td>2498.367676</td>\n      <td>-209774.968750</td>\n      <td>203598.757812</td>\n      <td>20451036.00</td>\n      <td>-20565104.00</td>\n      <td>413373.726562</td>\n      <td>1.570652e+06</td>\n      <td>1.570671e+06</td>\n      <td>361141.127856</td>\n      <td>2.217430</td>\n      <td>56.944785</td>\n      <td>13.093198</td>\n      <td>21.960636</td>\n      <td>-0.215193</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>-11676.998047</td>\n      <td>-3047.265625</td>\n      <td>-216341.558594</td>\n      <td>199429.820312</td>\n      <td>21108718.00</td>\n      <td>-19887192.00</td>\n      <td>415771.378906</td>\n      <td>1.572085e+06</td>\n      <td>1.572128e+06</td>\n      <td>370081.813992</td>\n      <td>2.219083</td>\n      <td>57.037977</td>\n      <td>13.426844</td>\n      <td>22.462923</td>\n      <td>0.021200</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>-5399.999512</td>\n      <td>-4674.824219</td>\n      <td>-215192.789062</td>\n      <td>203490.335938</td>\n      <td>20333708.00</td>\n      <td>-19361384.00</td>\n      <td>418683.125000</td>\n      <td>1.578421e+06</td>\n      <td>1.578431e+06</td>\n      <td>367818.445260</td>\n      <td>2.224674</td>\n      <td>55.281915</td>\n      <td>12.882231</td>\n      <td>22.662410</td>\n      <td>0.017587</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>1853.000366</td>\n      <td>5834.000000</td>\n      <td>-204767.660156</td>\n      <td>220689.300781</td>\n      <td>20530716.00</td>\n      <td>-29124400.00</td>\n      <td>425456.960938</td>\n      <td>1.595625e+06</td>\n      <td>1.595626e+06</td>\n      <td>368613.667144</td>\n      <td>2.231922</td>\n      <td>79.010635</td>\n      <td>18.252651</td>\n      <td>24.029214</td>\n      <td>-0.190509</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>-10221.999023</td>\n      <td>-7392.396484</td>\n      <td>-220528.042969</td>\n      <td>201759.277344</td>\n      <td>21356968.00</td>\n      <td>-18748084.00</td>\n      <td>422287.320312</td>\n      <td>1.579481e+06</td>\n      <td>1.579514e+06</td>\n      <td>370719.175906</td>\n      <td>2.219824</td>\n      <td>57.609558</td>\n      <td>13.521228</td>\n      <td>21.959184</td>\n      <td>0.154930</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>5451.000000</td>\n      <td>2641.799805</td>\n      <td>-201213.632812</td>\n      <td>212511.175781</td>\n      <td>19764536.00</td>\n      <td>-33838072.00</td>\n      <td>413724.808594</td>\n      <td>1.580166e+06</td>\n      <td>1.580175e+06</td>\n      <td>360252.569284</td>\n      <td>2.235467</td>\n      <td>93.928746</td>\n      <td>21.414127</td>\n      <td>25.201136</td>\n      <td>-0.182571</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>-735.998901</td>\n      <td>3732.281250</td>\n      <td>-200783.386719</td>\n      <td>194651.062500</td>\n      <td>20438080.00</td>\n      <td>-19650650.00</td>\n      <td>395434.449219</td>\n      <td>1.442635e+06</td>\n      <td>1.442635e+06</td>\n      <td>344631.078046</td>\n      <td>2.183255</td>\n      <td>59.304228</td>\n      <td>14.167184</td>\n      <td>21.545543</td>\n      <td>-0.119780</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>188.999969</td>\n      <td>285.617188</td>\n      <td>-47249.166992</td>\n      <td>47166.263672</td>\n      <td>3911730.00</td>\n      <td>-3661461.75</td>\n      <td>94415.430664</td>\n      <td>3.443763e+05</td>\n      <td>3.443763e+05</td>\n      <td>100944.548808</td>\n      <td>1.880099</td>\n      <td>38.751275</td>\n      <td>11.358881</td>\n      <td>8.673351</td>\n      <td>0.024364</td>\n      <td>No_cavitation</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>338.999817</td>\n      <td>442.606445</td>\n      <td>-50010.841797</td>\n      <td>50798.194336</td>\n      <td>3785041.25</td>\n      <td>-3834865.00</td>\n      <td>100809.036133</td>\n      <td>3.781361e+05</td>\n      <td>3.781363e+05</td>\n      <td>108410.954036</td>\n      <td>1.900190</td>\n      <td>35.373409</td>\n      <td>10.141488</td>\n      <td>9.288338</td>\n      <td>0.000133</td>\n      <td>No_cavitation</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>129.999954</td>\n      <td>116.105469</td>\n      <td>-49651.808594</td>\n      <td>50475.595703</td>\n      <td>3968321.25</td>\n      <td>-4272759.00</td>\n      <td>100127.404297</td>\n      <td>3.808784e+05</td>\n      <td>3.808784e+05</td>\n      <td>108591.544982</td>\n      <td>1.908602</td>\n      <td>39.347069</td>\n      <td>11.218172</td>\n      <td>9.769574</td>\n      <td>-0.027308</td>\n      <td>No_cavitation</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>-108.000008</td>\n      <td>-422.437500</td>\n      <td>-44462.881836</td>\n      <td>44095.830078</td>\n      <td>3280548.50</td>\n      <td>-3466732.00</td>\n      <td>88558.711914</td>\n      <td>3.258229e+05</td>\n      <td>3.258229e+05</td>\n      <td>93577.199859</td>\n      <td>1.908470</td>\n      <td>37.046759</td>\n      <td>10.639926</td>\n      <td>9.994113</td>\n      <td>-0.015095</td>\n      <td>No_cavitation</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>-486.000244</td>\n      <td>778.201172</td>\n      <td>-56428.169922</td>\n      <td>54220.079102</td>\n      <td>5136561.50</td>\n      <td>-4814440.00</td>\n      <td>110648.249023</td>\n      <td>4.449456e+05</td>\n      <td>4.449458e+05</td>\n      <td>125406.308389</td>\n      <td>1.921647</td>\n      <td>40.959355</td>\n      <td>11.544240</td>\n      <td>10.128421</td>\n      <td>0.016174</td>\n      <td>No_cavitation</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>-243.000031</td>\n      <td>-893.906250</td>\n      <td>-54796.658203</td>\n      <td>55363.051758</td>\n      <td>4646875.00</td>\n      <td>-5107823.00</td>\n      <td>110159.709961</td>\n      <td>4.117039e+05</td>\n      <td>4.117039e+05</td>\n      <td>120629.272148</td>\n      <td>1.897077</td>\n      <td>42.343147</td>\n      <td>12.406544</td>\n      <td>10.025000</td>\n      <td>0.029561</td>\n      <td>No_cavitation</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>141.999954</td>\n      <td>265.414062</td>\n      <td>-52241.909180</td>\n      <td>51704.750977</td>\n      <td>4342194.00</td>\n      <td>-4544057.50</td>\n      <td>103946.660156</td>\n      <td>4.032786e+05</td>\n      <td>4.032786e+05</td>\n      <td>113999.587863</td>\n      <td>1.907325</td>\n      <td>39.860298</td>\n      <td>11.267788</td>\n      <td>9.478155</td>\n      <td>0.014520</td>\n      <td>No_cavitation</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>-115.999985</td>\n      <td>736.753906</td>\n      <td>-53944.679688</td>\n      <td>54024.585938</td>\n      <td>4522007.50</td>\n      <td>-4376049.50</td>\n      <td>107969.265625</td>\n      <td>3.952932e+05</td>\n      <td>3.952932e+05</td>\n      <td>114491.338477</td>\n      <td>1.894048</td>\n      <td>39.496503</td>\n      <td>11.439630</td>\n      <td>9.425841</td>\n      <td>0.005057</td>\n      <td>No_cavitation</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>-369.999878</td>\n      <td>-646.807617</td>\n      <td>-45643.958008</td>\n      <td>44771.317383</td>\n      <td>4009059.25</td>\n      <td>-4061546.25</td>\n      <td>90415.275391</td>\n      <td>3.478693e+05</td>\n      <td>3.478695e+05</td>\n      <td>98666.054064</td>\n      <td>1.914248</td>\n      <td>41.164576</td>\n      <td>11.675488</td>\n      <td>9.878925</td>\n      <td>-0.009392</td>\n      <td>No_cavitation</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>-294.000122</td>\n      <td>-497.063477</td>\n      <td>-51091.940430</td>\n      <td>50301.433594</td>\n      <td>4094237.00</td>\n      <td>-4902808.00</td>\n      <td>101393.374023</td>\n      <td>3.858751e+05</td>\n      <td>3.858752e+05</td>\n      <td>111082.286592</td>\n      <td>1.893865</td>\n      <td>44.136722</td>\n      <td>12.705683</td>\n      <td>9.115134</td>\n      <td>0.015858</td>\n      <td>No_cavitation</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "\n",
    "def feature_pipe (datasets, splits_in_sec, label):\n",
    "    sr, df = read_wav(datasets)\n",
    "    df_split = splitting(sr[0],df, splits_in_sec)\n",
    "    freq, df_ftt = fourier_trans(sr[0],df_split)\n",
    "    output_df = feature_extraction(df_ftt, label)\n",
    "    return len(df_split), output_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kinos\\AppData\\Local\\Temp\\ipykernel_23192\\3207606025.py:6: WavFileWarning: Chunk (non-data) not understood, skipping it.\n",
      "  sf, d = wavfile.read(path/data)\n",
      "C:\\Users\\kinos\\AppData\\Local\\Temp\\ipykernel_23192\\3207606025.py:6: WavFileWarning: Chunk (non-data) not understood, skipping it.\n",
      "  sf, d = wavfile.read(path/data)\n"
     ]
    },
    {
     "data": {
      "text/plain": "           mean       median   quartile_25   quartile_75          Max  \\\n0    188.999985  -346.398438 -10175.405273   9655.065430   636732.250   \n0    857.999939   676.756958  -9252.479492   9865.675293   579818.125   \n0   -214.999954  -413.046875 -15554.760986  14128.928711  1108530.375   \n0   -311.999969   -44.036133  -8508.910645   8332.677002   546172.000   \n0    -52.999985   410.257080  -6458.427734   7189.333984   369466.750   \n..          ...          ...           ...           ...          ...   \n0   1110.999023  2798.148438 -61784.951172  69072.613281  4297929.000   \n0  -3284.000732 -5751.750000 -70404.218750  57803.674805  4430649.000   \n0   4189.000488  3295.250977 -60473.977539  65948.023438  4125214.000   \n0   4287.000000   994.078125 -56394.882812  67361.906250  4518601.000   \n0  -2134.000244  1471.269531 -60670.568359  56685.204102  3558102.250   \n\n             Min       quartile            std            rms            sra  \\\n0  -5.432184e+05   19830.470703   69138.546875   69138.804688   19829.180510   \n0  -4.631204e+05   19118.154785   66299.523438   66305.070312   19696.486031   \n0  -1.028691e+06   29683.689697  134435.593750  134435.765625   36059.243151   \n0  -5.955421e+05   16841.587646   62869.781250   62870.558594   16837.105111   \n0  -2.471501e+05   13647.761719   32047.134766   32047.177734   10662.855499   \n..           ...            ...            ...            ...            ...   \n0  -3.934186e+06  130857.564453  457513.062500  457514.406250  116254.121163   \n0  -5.511242e+06  128207.893555  457417.406250  457429.187500  116867.031044   \n0  -4.619242e+06  126422.000977  440707.312500  440727.218750  113204.543023   \n0  -4.024674e+06  123756.789062  411929.625000  411951.937500  107671.347722   \n0  -3.838522e+06  117355.772461  402268.718750  402274.343750  105906.350193   \n\n          ff        clf         cf   kurtosis      skew  Cavitation  \n0   1.890786  32.110871   9.209477   9.435697  0.111415         0.0  \n0   1.873086  29.437643   8.744702   8.041750  0.168401         0.0  \n0   1.941522  30.741920   8.245800   9.401334 -0.015968         0.0  \n0   1.978666  35.370815   9.472512  13.051699 -0.088088         0.0  \n0   1.810344  34.649888  11.528839  10.030529  0.053060         0.0  \n..       ...        ...        ...        ...       ...         ...  \n0   2.147027  36.970122   9.394085  18.069592  0.250297         1.0  \n0   2.157737  47.158227  12.048295  20.967020  0.393933         1.0  \n0   2.135276  40.804387  10.480955  18.464533 -0.172874         1.0  \n0   2.082933  41.966606  10.968758  17.227523  0.034508         1.0  \n0   2.070052  36.244496   9.542051  15.451439 -0.094267         1.0  \n\n[400 rows x 16 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>mean</th>\n      <th>median</th>\n      <th>quartile_25</th>\n      <th>quartile_75</th>\n      <th>Max</th>\n      <th>Min</th>\n      <th>quartile</th>\n      <th>std</th>\n      <th>rms</th>\n      <th>sra</th>\n      <th>ff</th>\n      <th>clf</th>\n      <th>cf</th>\n      <th>kurtosis</th>\n      <th>skew</th>\n      <th>Cavitation</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>188.999985</td>\n      <td>-346.398438</td>\n      <td>-10175.405273</td>\n      <td>9655.065430</td>\n      <td>636732.250</td>\n      <td>-5.432184e+05</td>\n      <td>19830.470703</td>\n      <td>69138.546875</td>\n      <td>69138.804688</td>\n      <td>19829.180510</td>\n      <td>1.890786</td>\n      <td>32.110871</td>\n      <td>9.209477</td>\n      <td>9.435697</td>\n      <td>0.111415</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>857.999939</td>\n      <td>676.756958</td>\n      <td>-9252.479492</td>\n      <td>9865.675293</td>\n      <td>579818.125</td>\n      <td>-4.631204e+05</td>\n      <td>19118.154785</td>\n      <td>66299.523438</td>\n      <td>66305.070312</td>\n      <td>19696.486031</td>\n      <td>1.873086</td>\n      <td>29.437643</td>\n      <td>8.744702</td>\n      <td>8.041750</td>\n      <td>0.168401</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>-214.999954</td>\n      <td>-413.046875</td>\n      <td>-15554.760986</td>\n      <td>14128.928711</td>\n      <td>1108530.375</td>\n      <td>-1.028691e+06</td>\n      <td>29683.689697</td>\n      <td>134435.593750</td>\n      <td>134435.765625</td>\n      <td>36059.243151</td>\n      <td>1.941522</td>\n      <td>30.741920</td>\n      <td>8.245800</td>\n      <td>9.401334</td>\n      <td>-0.015968</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>-311.999969</td>\n      <td>-44.036133</td>\n      <td>-8508.910645</td>\n      <td>8332.677002</td>\n      <td>546172.000</td>\n      <td>-5.955421e+05</td>\n      <td>16841.587646</td>\n      <td>62869.781250</td>\n      <td>62870.558594</td>\n      <td>16837.105111</td>\n      <td>1.978666</td>\n      <td>35.370815</td>\n      <td>9.472512</td>\n      <td>13.051699</td>\n      <td>-0.088088</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>-52.999985</td>\n      <td>410.257080</td>\n      <td>-6458.427734</td>\n      <td>7189.333984</td>\n      <td>369466.750</td>\n      <td>-2.471501e+05</td>\n      <td>13647.761719</td>\n      <td>32047.134766</td>\n      <td>32047.177734</td>\n      <td>10662.855499</td>\n      <td>1.810344</td>\n      <td>34.649888</td>\n      <td>11.528839</td>\n      <td>10.030529</td>\n      <td>0.053060</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>1110.999023</td>\n      <td>2798.148438</td>\n      <td>-61784.951172</td>\n      <td>69072.613281</td>\n      <td>4297929.000</td>\n      <td>-3.934186e+06</td>\n      <td>130857.564453</td>\n      <td>457513.062500</td>\n      <td>457514.406250</td>\n      <td>116254.121163</td>\n      <td>2.147027</td>\n      <td>36.970122</td>\n      <td>9.394085</td>\n      <td>18.069592</td>\n      <td>0.250297</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>-3284.000732</td>\n      <td>-5751.750000</td>\n      <td>-70404.218750</td>\n      <td>57803.674805</td>\n      <td>4430649.000</td>\n      <td>-5.511242e+06</td>\n      <td>128207.893555</td>\n      <td>457417.406250</td>\n      <td>457429.187500</td>\n      <td>116867.031044</td>\n      <td>2.157737</td>\n      <td>47.158227</td>\n      <td>12.048295</td>\n      <td>20.967020</td>\n      <td>0.393933</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>4189.000488</td>\n      <td>3295.250977</td>\n      <td>-60473.977539</td>\n      <td>65948.023438</td>\n      <td>4125214.000</td>\n      <td>-4.619242e+06</td>\n      <td>126422.000977</td>\n      <td>440707.312500</td>\n      <td>440727.218750</td>\n      <td>113204.543023</td>\n      <td>2.135276</td>\n      <td>40.804387</td>\n      <td>10.480955</td>\n      <td>18.464533</td>\n      <td>-0.172874</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>4287.000000</td>\n      <td>994.078125</td>\n      <td>-56394.882812</td>\n      <td>67361.906250</td>\n      <td>4518601.000</td>\n      <td>-4.024674e+06</td>\n      <td>123756.789062</td>\n      <td>411929.625000</td>\n      <td>411951.937500</td>\n      <td>107671.347722</td>\n      <td>2.082933</td>\n      <td>41.966606</td>\n      <td>10.968758</td>\n      <td>17.227523</td>\n      <td>0.034508</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>-2134.000244</td>\n      <td>1471.269531</td>\n      <td>-60670.568359</td>\n      <td>56685.204102</td>\n      <td>3558102.250</td>\n      <td>-3.838522e+06</td>\n      <td>117355.772461</td>\n      <td>402268.718750</td>\n      <td>402274.343750</td>\n      <td>105906.350193</td>\n      <td>2.070052</td>\n      <td>36.244496</td>\n      <td>9.542051</td>\n      <td>15.451439</td>\n      <td>-0.094267</td>\n      <td>1.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>400 rows Ã— 16 columns</p>\n</div>"
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "No_cav_files = [\"sxmany_200206_007_HKMNetzpumpe04_004_RP1_FC_01_C06_SB1_L0_XX_XXXX_YY_YYYY_ZZZZZZ_10.wav\"]\n",
    "cav_files = [\"s00000_191115_007_KesselpumpHD02_002_RP1_FC_01_P06_SB1_L0_KS_XXXX_YY_YYYY_ZZZZZZ_16.wav\"]\n",
    "\n",
    "\n",
    "no_cav_df = feature_pipe(No_cav_files,0.1,\"No Cavitation\")[1]\n",
    "cav_df = feature_pipe(cav_files,0.1,\"Cavitation\")[1]\n",
    "final_df = pd.concat([no_cav_df, cav_df])\n",
    "final_df.astype('float')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "XGBOOST\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:58:37] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "XGBClassifier(base_score=0.5, booster='gbtree', callbacks=None,\n",
      "              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=0.4,\n",
      "              early_stopping_rounds=None, enable_categorical=False,\n",
      "              eval_metric=None, gamma=10, gpu_id=-1, grow_policy='depthwise',\n",
      "              importance_type=None, interaction_constraints='',\n",
      "              learning_rate=0.01, max_bin=256, max_cat_to_onehot=4,\n",
      "              max_delta_step=0, max_depth=4, max_leaves=0, min_child_weight=1,\n",
      "              missing=nan, monotone_constraints='()', n_estimators=1000,\n",
      "              n_jobs=0, num_parallel_tree=1, predictor='auto', random_state=0,\n",
      "              reg_alpha=0.3, reg_lambda=1, ...)\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "y = final_df[\"Cavitation\"]\n",
    "X = final_df.loc[:, final_df.columns != 'Cavitation'].astype('float')\n",
    "\n",
    "X_train,X_test,y_train,y_test= train_test_split(X, y, test_size=0.3, random_state=1623806)\n",
    "\n",
    "\n",
    "\n",
    "gbm_param_grid = {\n",
    "    'clf__learning_rate': np.arange(.05, 1, .05),\n",
    "    'clf__max_depth': np.arange(3,10, 1),\n",
    "    'clf__n_estimators': np.arange(50, 200, 50)\n",
    "}\n",
    "#model = xgb.XGBClassifier()\n",
    "\n",
    "model = xgb.XGBClassifier(silent=False,\n",
    "                      scale_pos_weight=1,\n",
    "                      learning_rate=0.01,\n",
    "                      colsample_bytree = 0.4,\n",
    "                      subsample = 0.8,\n",
    "                      objective='binary:logistic',\n",
    "                      n_estimators=1000,\n",
    "                      reg_alpha = 0.3,\n",
    "                      max_depth=4,\n",
    "                      gamma=10)\n",
    "model.fit(X_train, y_train)\n",
    "print(model)\n",
    "predicted_y = model.predict(X_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "data": {
      "text/plain": "       Variable  Importance\n9           sra    0.175304\n8           rms    0.152863\n3   quartile_75    0.130172\n4           Max    0.128870\n2   quartile_25    0.123222\n6      quartile    0.108041\n5           Min    0.105834\n7           std    0.075695\n0          mean    0.000000\n1        median    0.000000\n10           ff    0.000000\n11          clf    0.000000\n12           cf    0.000000\n13     kurtosis    0.000000\n14         skew    0.000000",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Variable</th>\n      <th>Importance</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>9</th>\n      <td>sra</td>\n      <td>0.175304</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>rms</td>\n      <td>0.152863</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>quartile_75</td>\n      <td>0.130172</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Max</td>\n      <td>0.128870</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>quartile_25</td>\n      <td>0.123222</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>quartile</td>\n      <td>0.108041</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>Min</td>\n      <td>0.105834</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>std</td>\n      <td>0.075695</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>mean</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>median</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>ff</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>clf</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>cf</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>kurtosis</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>skew</td>\n      <td>0.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({'Variable':X.columns,\n",
    "              'Importance':model.feature_importances_}).sort_values('Importance', ascending=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        57\n",
      "           1       1.00      1.00      1.00        63\n",
      "\n",
      "    accuracy                           1.00       120\n",
      "   macro avg       1.00      1.00      1.00       120\n",
      "weighted avg       1.00      1.00      1.00       120\n",
      "\n",
      "[[57  0]\n",
      " [ 0 63]]\n"
     ]
    },
    {
     "data": {
      "text/plain": "1.0"
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.metrics import precision_recall_fscore_support as score\n",
    "print(metrics.classification_report(y_test, predicted_y))\n",
    "print(metrics.confusion_matrix(y_test, predicted_y))\n",
    "precision,recall,fscore,support=score(y_test,predicted_y,average='macro')\n",
    "eval= metrics.classification_report(y_test, predicted_y, output_dict=True)\n",
    "eval['macro avg']['f1-score']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [
    "\n",
    "def Classification_pipe (splits_in_sec, cavitation_data, no_cavitation_data,test_split_ratio ):\n",
    "\n",
    "    non_cav_len, no_cav_df = feature_pipe(no_cavitation_data,splits_in_sec,\"No Cavitation\")\n",
    "    cav_len, cav_df = feature_pipe(cavitation_data,splits_in_sec,\"Cavitation\")\n",
    "    final_df = pd.concat([no_cav_df, cav_df])\n",
    "\n",
    "    y = final_df[\"Cavitation\"]\n",
    "    X = final_df.loc[:, final_df.columns != 'Cavitation'].astype('float')\n",
    "\n",
    "\n",
    "    X_train,X_test,y_train,y_test = train_test_split(X, y, test_size = test_split_ratio, random_state = 1623806)\n",
    "\n",
    "    model = xgb.XGBClassifier()\n",
    "    model.fit(X_train, y_train)\n",
    "    print(model)\n",
    "\n",
    "    predicted_y = model.predict(X_test)\n",
    "    print(metrics.classification_report(y_test, predicted_y))\n",
    "    print(metrics.confusion_matrix(y_test, predicted_y))\n",
    "    return metrics.confusion_matrix(y_test, predicted_y)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kinos\\AppData\\Local\\Temp\\ipykernel_23192\\3207606025.py:6: WavFileWarning: Chunk (non-data) not understood, skipping it.\n",
      "  sf, d = wavfile.read(path/data)\n",
      "C:\\Users\\kinos\\AppData\\Local\\Temp\\ipykernel_23192\\3207606025.py:6: WavFileWarning: Chunk (non-data) not understood, skipping it.\n",
      "  sf, d = wavfile.read(path/data)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBClassifier(base_score=0.5, booster='gbtree', callbacks=None,\n",
      "              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
      "              early_stopping_rounds=None, enable_categorical=False,\n",
      "              eval_metric=None, gamma=0, gpu_id=-1, grow_policy='depthwise',\n",
      "              importance_type=None, interaction_constraints='',\n",
      "              learning_rate=0.300000012, max_bin=256, max_cat_to_onehot=4,\n",
      "              max_delta_step=0, max_depth=6, max_leaves=0, min_child_weight=1,\n",
      "              missing=nan, monotone_constraints='()', n_estimators=100,\n",
      "              n_jobs=0, num_parallel_tree=1, predictor='auto', random_state=0,\n",
      "              reg_alpha=0, reg_lambda=1, ...)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         4\n",
      "           1       1.00      1.00      1.00         8\n",
      "\n",
      "    accuracy                           1.00        12\n",
      "   macro avg       1.00      1.00      1.00        12\n",
      "weighted avg       1.00      1.00      1.00        12\n",
      "\n",
      "[[4 0]\n",
      " [0 8]]\n"
     ]
    },
    {
     "data": {
      "text/plain": "array([[4, 0],\n       [0, 8]], dtype=int64)"
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "No_cav_files = [\"sxmany_200206_007_HKMNetzpumpe04_004_RP1_FC_01_C06_SB1_L0_XX_XXXX_YY_YYYY_ZZZZZZ_10.wav\"]\n",
    "cav_files = [\"s00000_191115_007_KesselpumpHD02_002_RP1_FC_01_P06_SB1_L0_KS_XXXX_YY_YYYY_ZZZZZZ_16.wav\"]\n",
    "\n",
    "Classification_pipe(1, cav_files, No_cav_files, 0.3)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "def Classification_pipe_Grid (splits_in_sec, cavitation_data, no_cavitation_data,test_split_ratio ):\n",
    "    #read in files\n",
    "    print(f'\\n Reading in files, splitting in {splits_in_sec} second samples, transforming and extracting features')\n",
    "    non_cav_len, no_cav_df = feature_pipe(no_cavitation_data,splits_in_sec,\"No Cavitation\")\n",
    "    cav_len, cav_df = feature_pipe(cavitation_data,splits_in_sec,\"Cavitation\")\n",
    "    final_df = pd.concat([no_cav_df, cav_df])\n",
    "    length = cav_len + non_cav_len\n",
    "    print(f'\\n Done! We have {length} samples!')\n",
    "    #y = final_df[\"Cavitation\"]\n",
    "    #X = final_df.loc[:, final_df.columns != 'Cavitation'].astype('float')\n",
    "    #split in train test, keep for output\n",
    "\n",
    "    train, test = train_test_split(final_df, test_size = test_split_ratio, random_state = 1623806)\n",
    "    X_train = train.loc[:, final_df.columns != 'Cavitation'].astype('float')\n",
    "    X_test = test.loc[:, final_df.columns != 'Cavitation'].astype('float')\n",
    "    y_train = train[\"Cavitation\"]\n",
    "    y_test = test[\"Cavitation\"]\n",
    "\n",
    "\n",
    "\n",
    "    print(f'\\n Train set: {len(train)} samples!')\n",
    "    print(f'\\n Test set: {len(test)} samples!')\n",
    "    print('\\n Starting Gridsearch, fine tuning parameters')\n",
    "    model = xgb.XGBClassifier()\n",
    "    #parameters for gridsearch\n",
    "    param = {\n",
    "    'max_depth': range (2, 10, 1),\n",
    "    'n_estimators': range(100, 1000, 100),\n",
    "    'learning_rate': [0.1, 0.01, 0.05]\n",
    "}\n",
    "    grid = GridSearchCV(model, param, n_jobs=5,\n",
    "                    cv = 10,\n",
    "                       #StratifiedKFold( n_splits=5, shuffle=True),\n",
    "                       scoring='roc_auc', verbose=True, refit=True)\n",
    "\n",
    "    grid.fit(X_train, y_train)\n",
    "    #Output\n",
    "    print('\\n Best estimator:')\n",
    "    print(grid.best_estimator_)\n",
    "    print('\\n  best_score_:')\n",
    "    print(grid.best_score_)\n",
    "    print('\\n Best parameters:')\n",
    "    print(grid.best_params_)\n",
    "\n",
    "    predicted_y = grid.predict(X_test)\n",
    "\n",
    "    print('\\n Classification report on unseen test set:')\n",
    "    print(metrics.classification_report(y_test, predicted_y))\n",
    "    print('\\n Confusion matrix on unseen test set')\n",
    "    print(metrics.confusion_matrix(y_test, predicted_y))\n",
    "    print(X_train.columns)\n",
    "    print(grid.best_estimator_.feature_importances_)\n",
    "    importance = pd.DataFrame({'Variable':X.columns,\n",
    "              'Importance':grid.best_estimator_.feature_importances_}).sort_values('Importance', ascending=False)\n",
    "    print('\\n Feature importance:')\n",
    "    print(importance)\n",
    "    return train, test, grid.best_estimator_, importance\n",
    "   # predicted_y = model.predict(X_test)\n",
    "   # print(metrics.classification_report(y_test, predicted_y))\n",
    "   # print(metrics.confusion_matrix(y_test, predicted_y))\n",
    "   # return metrics.confusion_matrix(y_test, predicted_y)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Reading in files, splitting in 1 second samples, transforming and extracting features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kinos\\AppData\\Local\\Temp\\ipykernel_23192\\3207606025.py:6: WavFileWarning: Chunk (non-data) not understood, skipping it.\n",
      "  sf, d = wavfile.read(path/data)\n",
      "C:\\Users\\kinos\\AppData\\Local\\Temp\\ipykernel_23192\\3207606025.py:6: WavFileWarning: Chunk (non-data) not understood, skipping it.\n",
      "  sf, d = wavfile.read(path/data)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Done! We have 40 samples!\n",
      "\n",
      " Train set: 28 samples!\n",
      "\n",
      " Test set: 12 samples!\n",
      "\n",
      " Starting Gridsearch, fine tuning parameters\n",
      "Fitting 10 folds for each of 216 candidates, totalling 2160 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train, test, best_model, x = Classification_pipe_Grid(1, cav_files, No_cav_files, 0.3)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "best_model.predict(X_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "metrics.confusion_matrix(y_test, model.predict(X_test))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We only two datasets for each label which may be homogenous, especially the cavitation set.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [],
   "source": [
    "def xg_boost_pipe(df,test_split, param, grid: bool = False):\n",
    "    train, test = train_test_split(df, test_size = test_split, random_state = 1623806)\n",
    "    X_train = train.loc[:, df.columns != 'Cavitation'].astype('float')\n",
    "    X_test = test.loc[:, df.columns != 'Cavitation'].astype('float')\n",
    "    y_train = train[\"Cavitation\"]\n",
    "    y_test = test[\"Cavitation\"]\n",
    "    print(f'\\n Train set: {len(train)} samples!')\n",
    "    print(f'\\n Test set: {len(test)} samples!')\n",
    "\n",
    "    if grid == True:\n",
    "        model = xgb.XGBClassifier(objective = 'binary:logistic')\n",
    "        print('\\n Initiating Gridsearch, fine tuning parameters')\n",
    "        grid = GridSearchCV(model, param, n_jobs=5,\n",
    "                        cv = 10,\n",
    "                           #StratifiedKFold( n_splits=5, shuffle=True),\n",
    "                           scoring='roc_auc', verbose=True, refit=True)\n",
    "\n",
    "        grid.fit(X_train, y_train)\n",
    "        #Output\n",
    "        print('\\n Done!')\n",
    "        print('\\n Best estimator:')\n",
    "        print(grid.best_estimator_)\n",
    "        print('\\n  best_score_:')\n",
    "        print(grid.best_score_)\n",
    "        print('\\n Best parameters:')\n",
    "        print(grid.best_params_)\n",
    "\n",
    "        predicted_y = grid.predict(X_test)\n",
    "\n",
    "        importance = pd.DataFrame({'Variable':X_train.columns,\n",
    "                  'Importance':grid.best_estimator_.feature_importances_}).sort_values('Importance', ascending=False)\n",
    "        print('\\n Feature importance:')\n",
    "        print(importance)\n",
    "\n",
    "        return train, test, grid.best_estimator_, predicted_y, importance\n",
    "    else:\n",
    "\n",
    "        print(f'\\n Train set: {len(train)} samples!,  Test set: {len(test)} samples!')\n",
    "        model = xgb.XGBClassifier()\n",
    "        model.fit(X_train, y_train)\n",
    "        predicted_y = model.predict(X_test)\n",
    "        evaluation = metrics.classification_report(y_test, predicted_y, output_dict=True)\n",
    "\n",
    "        return train, test, model , predicted_y, evaluation\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "\n",
    "split_eval_list = np.arange(0.1,1,0.1)\n",
    "def Classification_pipe_all (splits_in_sec, cavitation_data, no_cavitation_data,test_split_ratio, evaluation = \"accuracy\" , split_eval: bool = False):\n",
    "    #read in files\n",
    "    print(f'\\n Reading in files, splitting in {splits_in_sec} second samples, transforming and extracting features')\n",
    "    paramameter = {\n",
    "            'max_depth': range (2, 10, 1),\n",
    "            'n_estimators': range(100, 1000, 100),\n",
    "            'learning_rate': [0.1, 0.01, 0.05]\n",
    "        }\n",
    "    if split_eval == True:\n",
    "        print(f\"splitting evaluation is set to true, range is {splits_in_sec}\")\n",
    "        print(f\"\\n Evaluation method is {evaluation}\")\n",
    "        f1_result = []\n",
    "        acc_result = []\n",
    "        sample_size_list = []\n",
    "        splits_list = []\n",
    "\n",
    "        # loop all splits and get scores\n",
    "        for splits in split_eval_list:\n",
    "            splits_list.append(splits)\n",
    "            non_cav_len, no_cav_df = feature_pipe(no_cavitation_data,splits,\"No Cavitation\")\n",
    "            cav_len, cav_df = feature_pipe(cavitation_data,splits,\"Cavitation\")\n",
    "            final_df = pd.concat([no_cav_df, cav_df])\n",
    "            length = cav_len + non_cav_len\n",
    "            sample_size_list.append(length)\n",
    "            print(f\"{splits} second splits\")\n",
    "\n",
    "            #start xg boost no grid\n",
    "            train, test, model, predicted_y, eval = xg_boost_pipe(final_df, test_split_ratio, paramameter, grid = False)\n",
    "\n",
    "            print(f'\\n Classification report on unseen test set:')\n",
    "            print(f\"\\n accuracy:{eval['accuracy']}, f1: {eval['macro avg']['f1-score']}\")\n",
    "            f1_result.append(eval['macro avg']['f1-score'])\n",
    "            acc_result.append(eval[\"accuracy\"])\n",
    "            print(f'\\n -------------------------------------')\n",
    "        zipped = list(zip(splits_list, sample_size_list, f1_result, acc_result,  ))\n",
    "        output = pd.DataFrame(zipped, columns=['Splits_in_sec', 'Sample_size', 'f1', 'accuracy'])\n",
    "\n",
    "\n",
    "        #get best model using evaluator f1\n",
    "        if evaluation == \"f1\":\n",
    "            optim = output.loc[output['f1'].idxmax(), 'Splits_in_sec']\n",
    "\n",
    "            print(f\"\\n RESULT split evaulation based on {evaluation} best split size is {optim} seconds!\")\n",
    "\n",
    "            non_cav_len, no_cav_df = feature_pipe(no_cavitation_data,optim,\"No Cavitation\")\n",
    "            cav_len, cav_df = feature_pipe(cavitation_data,splits,\"Cavitation\")\n",
    "            final_df = pd.concat([no_cav_df, cav_df])\n",
    "\n",
    "\n",
    "            #start xg boost gridsearch for final model\n",
    "            train, test, model, predicted_y, importance = xg_boost_pipe(final_df, test_split_ratio, paramameter, grid = True)\n",
    "\n",
    "\n",
    "            print(f'\\n Classification report on unseen test set:')\n",
    "            print(f\"\\n accuracy:{eval['accuracy']}, f1: {eval['macro avg']['f1-score']}\")\n",
    "\n",
    "            return train, test, model, output\n",
    "        #get best model using evaluator accuracy\n",
    "        if evaluation == \"accuracy\":\n",
    "\n",
    "            optim = output.loc[output['accuracy'].idxmax(), 'Splits_in_sec']\n",
    "            print(f\"\\n RESULT split evaulation based on {evaluation} best split size is {optim} seconds!\")\n",
    "            non_cav_len, no_cav_df = feature_pipe(no_cavitation_data,optim,\"No Cavitation\")\n",
    "            cav_len, cav_df = feature_pipe(cavitation_data,splits,\"Cavitation\")\n",
    "            final_df = pd.concat([no_cav_df, cav_df])\n",
    "            #start xg boost gridsearch for final model\n",
    "            train, test, model, predicted_y, importance = xg_boost_pipe(final_df, test_split_ratio, paramameter, grid = True)\n",
    "\n",
    "            print(f'\\n Classification report on unseen test set:')\n",
    "            print(f\"\\n accuracy:{eval['accuracy']}, f1: {eval['macro avg']['f1-score']}\")\n",
    "\n",
    "            return train, test, model, output\n",
    "\n",
    "\n",
    "\n",
    "    # if no split evaluation, only grid search\n",
    "    else:\n",
    "        if isinstance(split_eval,np.ndarray):\n",
    "            print(\"This is of type np.ndarray. Only input one variable when split evaluation is set to false.\")\n",
    "        else:\n",
    "            non_cav_len, no_cav_df = feature_pipe(no_cavitation_data,splits_in_sec,\"No Cavitation\")\n",
    "            cav_len, cav_df = feature_pipe(cavitation_data,splits_in_sec,\"Cavitation\")\n",
    "            final_df = pd.concat([no_cav_df, cav_df])\n",
    "            length = cav_len + non_cav_len\n",
    "            print(f'\\n Done! We have {length} samples!')\n",
    "\n",
    "\n",
    "            train, test, model, predicted_y, importance = xg_boost_pipe(final_df, test_split_ratio, paramameter, grid = True)\n",
    "\n",
    "\n",
    "\n",
    "            return train, test, model, importance\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [],
   "source": [
    "#train, test, model, eval_df  = Classification_pipe_all (1,  cav_files, No_cav_files, 0.3 , evaluation = \"accuracy\" , split_eval =False) #single no grid training"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kinos\\AppData\\Local\\Temp\\ipykernel_23192\\3207606025.py:6: WavFileWarning: Chunk (non-data) not understood, skipping it.\n",
      "  sf, d = wavfile.read(path/data)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Reading in files, splitting in [0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9] second samples, transforming and extracting features\n",
      "splitting evaluation is set to true, range is [0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9]\n",
      "\n",
      " Evaluation method is accuracy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kinos\\AppData\\Local\\Temp\\ipykernel_23192\\3207606025.py:6: WavFileWarning: Chunk (non-data) not understood, skipping it.\n",
      "  sf, d = wavfile.read(path/data)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1 second splits\n",
      "\n",
      " Train set: 280 samples!\n",
      "\n",
      " Test set: 120 samples!\n",
      "\n",
      " Train set: 280 samples!,  Test set: 120 samples!\n",
      "\n",
      " Classification report on unseen test set:\n",
      "\n",
      " accuracy:1.0, f1: 1.0\n",
      "\n",
      " -------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kinos\\AppData\\Local\\Temp\\ipykernel_23192\\3207606025.py:6: WavFileWarning: Chunk (non-data) not understood, skipping it.\n",
      "  sf, d = wavfile.read(path/data)\n",
      "C:\\Users\\kinos\\AppData\\Local\\Temp\\ipykernel_23192\\3207606025.py:6: WavFileWarning: Chunk (non-data) not understood, skipping it.\n",
      "  sf, d = wavfile.read(path/data)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2 second splits\n",
      "\n",
      " Train set: 140 samples!\n",
      "\n",
      " Test set: 60 samples!\n",
      "\n",
      " Train set: 140 samples!,  Test set: 60 samples!\n",
      "\n",
      " Classification report on unseen test set:\n",
      "\n",
      " accuracy:1.0, f1: 1.0\n",
      "\n",
      " -------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kinos\\AppData\\Local\\Temp\\ipykernel_23192\\3207606025.py:6: WavFileWarning: Chunk (non-data) not understood, skipping it.\n",
      "  sf, d = wavfile.read(path/data)\n",
      "C:\\Users\\kinos\\AppData\\Local\\Temp\\ipykernel_23192\\3207606025.py:6: WavFileWarning: Chunk (non-data) not understood, skipping it.\n",
      "  sf, d = wavfile.read(path/data)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.30000000000000004 second splits\n",
      "\n",
      " Train set: 93 samples!\n",
      "\n",
      " Test set: 41 samples!\n",
      "\n",
      " Train set: 93 samples!,  Test set: 41 samples!\n",
      "\n",
      " Classification report on unseen test set:\n",
      "\n",
      " accuracy:0.975609756097561, f1: 0.975609756097561\n",
      "\n",
      " -------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kinos\\AppData\\Local\\Temp\\ipykernel_23192\\3207606025.py:6: WavFileWarning: Chunk (non-data) not understood, skipping it.\n",
      "  sf, d = wavfile.read(path/data)\n",
      "C:\\Users\\kinos\\AppData\\Local\\Temp\\ipykernel_23192\\3207606025.py:6: WavFileWarning: Chunk (non-data) not understood, skipping it.\n",
      "  sf, d = wavfile.read(path/data)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4 second splits\n",
      "\n",
      " Train set: 70 samples!\n",
      "\n",
      " Test set: 30 samples!\n",
      "\n",
      " Train set: 70 samples!,  Test set: 30 samples!\n",
      "\n",
      " Classification report on unseen test set:\n",
      "\n",
      " accuracy:1.0, f1: 1.0\n",
      "\n",
      " -------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kinos\\AppData\\Local\\Temp\\ipykernel_23192\\3207606025.py:6: WavFileWarning: Chunk (non-data) not understood, skipping it.\n",
      "  sf, d = wavfile.read(path/data)\n",
      "C:\\Users\\kinos\\AppData\\Local\\Temp\\ipykernel_23192\\3207606025.py:6: WavFileWarning: Chunk (non-data) not understood, skipping it.\n",
      "  sf, d = wavfile.read(path/data)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5 second splits\n",
      "\n",
      " Train set: 56 samples!\n",
      "\n",
      " Test set: 24 samples!\n",
      "\n",
      " Train set: 56 samples!,  Test set: 24 samples!\n",
      "\n",
      " Classification report on unseen test set:\n",
      "\n",
      " accuracy:1.0, f1: 1.0\n",
      "\n",
      " -------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kinos\\AppData\\Local\\Temp\\ipykernel_23192\\3207606025.py:6: WavFileWarning: Chunk (non-data) not understood, skipping it.\n",
      "  sf, d = wavfile.read(path/data)\n",
      "C:\\Users\\kinos\\AppData\\Local\\Temp\\ipykernel_23192\\3207606025.py:6: WavFileWarning: Chunk (non-data) not understood, skipping it.\n",
      "  sf, d = wavfile.read(path/data)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6 second splits\n",
      "\n",
      " Train set: 47 samples!\n",
      "\n",
      " Test set: 21 samples!\n",
      "\n",
      " Train set: 47 samples!,  Test set: 21 samples!\n",
      "\n",
      " Classification report on unseen test set:\n",
      "\n",
      " accuracy:0.9523809523809523, f1: 0.9519450800915332\n",
      "\n",
      " -------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kinos\\AppData\\Local\\Temp\\ipykernel_23192\\3207606025.py:6: WavFileWarning: Chunk (non-data) not understood, skipping it.\n",
      "  sf, d = wavfile.read(path/data)\n",
      "C:\\Users\\kinos\\AppData\\Local\\Temp\\ipykernel_23192\\3207606025.py:6: WavFileWarning: Chunk (non-data) not understood, skipping it.\n",
      "  sf, d = wavfile.read(path/data)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7000000000000001 second splits\n",
      "\n",
      " Train set: 40 samples!\n",
      "\n",
      " Test set: 18 samples!\n",
      "\n",
      " Train set: 40 samples!,  Test set: 18 samples!\n",
      "\n",
      " Classification report on unseen test set:\n",
      "\n",
      " accuracy:1.0, f1: 1.0\n",
      "\n",
      " -------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kinos\\AppData\\Local\\Temp\\ipykernel_23192\\3207606025.py:6: WavFileWarning: Chunk (non-data) not understood, skipping it.\n",
      "  sf, d = wavfile.read(path/data)\n",
      "C:\\Users\\kinos\\AppData\\Local\\Temp\\ipykernel_23192\\3207606025.py:6: WavFileWarning: Chunk (non-data) not understood, skipping it.\n",
      "  sf, d = wavfile.read(path/data)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8 second splits\n",
      "\n",
      " Train set: 35 samples!\n",
      "\n",
      " Test set: 15 samples!\n",
      "\n",
      " Train set: 35 samples!,  Test set: 15 samples!\n",
      "\n",
      " Classification report on unseen test set:\n",
      "\n",
      " accuracy:1.0, f1: 1.0\n",
      "\n",
      " -------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kinos\\AppData\\Local\\Temp\\ipykernel_23192\\3207606025.py:6: WavFileWarning: Chunk (non-data) not understood, skipping it.\n",
      "  sf, d = wavfile.read(path/data)\n",
      "C:\\Users\\kinos\\AppData\\Local\\Temp\\ipykernel_23192\\3207606025.py:6: WavFileWarning: Chunk (non-data) not understood, skipping it.\n",
      "  sf, d = wavfile.read(path/data)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9 second splits\n",
      "\n",
      " Train set: 32 samples!\n",
      "\n",
      " Test set: 14 samples!\n",
      "\n",
      " Train set: 32 samples!,  Test set: 14 samples!\n",
      "\n",
      " Classification report on unseen test set:\n",
      "\n",
      " accuracy:0.9285714285714286, f1: 0.9251336898395721\n",
      "\n",
      " -------------------------------------\n",
      "\n",
      " RESULT split evaulation based on accuracy best split size is 0.1 seconds!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kinos\\AppData\\Local\\Temp\\ipykernel_23192\\3207606025.py:6: WavFileWarning: Chunk (non-data) not understood, skipping it.\n",
      "  sf, d = wavfile.read(path/data)\n",
      "C:\\Users\\kinos\\AppData\\Local\\Temp\\ipykernel_23192\\3207606025.py:6: WavFileWarning: Chunk (non-data) not understood, skipping it.\n",
      "  sf, d = wavfile.read(path/data)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Train set: 156 samples!\n",
      "\n",
      " Test set: 67 samples!\n",
      "\n",
      " Initiating Gridsearch, fine tuning parameters\n",
      "Fitting 10 folds for each of 216 candidates, totalling 2160 fits\n",
      "\n",
      " Done!\n",
      "\n",
      " Best estimator:\n",
      "XGBClassifier(base_score=0.5, booster='gbtree', callbacks=None,\n",
      "              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
      "              early_stopping_rounds=None, enable_categorical=False,\n",
      "              eval_metric=None, gamma=0, gpu_id=-1, grow_policy='depthwise',\n",
      "              importance_type=None, interaction_constraints='',\n",
      "              learning_rate=0.1, max_bin=256, max_cat_to_onehot=4,\n",
      "              max_delta_step=0, max_depth=2, max_leaves=0, min_child_weight=1,\n",
      "              missing=nan, monotone_constraints='()', n_estimators=100,\n",
      "              n_jobs=0, num_parallel_tree=1, predictor='auto', random_state=0,\n",
      "              reg_alpha=0, reg_lambda=1, ...)\n",
      "\n",
      "  best_score_:\n",
      "1.0\n",
      "\n",
      " Best parameters:\n",
      "{'learning_rate': 0.1, 'max_depth': 2, 'n_estimators': 100}\n",
      "\n",
      " Feature importance:\n",
      "       Variable  Importance\n",
      "2   quartile_25    0.711571\n",
      "10           ff    0.073444\n",
      "4           Max    0.048499\n",
      "5           Min    0.043772\n",
      "7           std    0.041469\n",
      "3   quartile_75    0.028192\n",
      "11          clf    0.026714\n",
      "12           cf    0.026339\n",
      "0          mean    0.000000\n",
      "1        median    0.000000\n",
      "6      quartile    0.000000\n",
      "8           rms    0.000000\n",
      "9           sra    0.000000\n",
      "13     kurtosis    0.000000\n",
      "14         skew    0.000000\n",
      "\n",
      " Classification report on unseen test set:\n",
      "\n",
      " accuracy:0.9285714285714286, f1: 0.9251336898395721\n"
     ]
    }
   ],
   "source": [
    "train, test, model, eval_df  = Classification_pipe_all (split_eval_list,  cav_files, No_cav_files, 0.3 , evaluation = \"accuracy\" , split_eval =True) #grid, splits eval training"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "eval_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}